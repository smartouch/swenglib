<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:ContentDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmlns:epf="http://www.eclipse.org/epf" epf:version="1.5.1" xmlns:rmc="http://www.ibm.com/rmc" rmc:version="7.5.1" xmi:id="-9z9HGhrkSiIWgqK5rxkc-w" name="new_guideline,_ODuDELJZEdyHw6xErAkVmw" guid="-9z9HGhrkSiIWgqK5rxkc-w" changeDate="2007-12-24T11:52:30.171-0800" version="7.2.0">
  <mainDescription>&lt;h3>&#xD;
    Identify Test Infrastructure Elements&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    &lt;strong>Facilitate common test scenarios&lt;/strong>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Some tests have a common structure to the scenario or procedure followed when they are executed, but the same procedure&#xD;
    needs to be conducted many times against different test target items. In the case of test automation, it can be useful&#xD;
    to create common test scripts or utility functions that can be reused in many different contexts, in order to undertake&#xD;
    these common test scenarios in an efficient way. This provides a central point of modification if the test scenario&#xD;
    needs to be altered. Examples include conducting standard boundary tests on appropriate classes of interface elements,&#xD;
    and validating UI elements for adherence to UI design standards.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;strong>Facilitate test data dependencies&lt;/strong>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    When tests are to be conducted in a given test environment configuration, there is the potential for conflicts in the&#xD;
    test data values that are used. This problem is compounded when the environment is shared by multiple test team&#xD;
    members. Consider using a data-driven approach that uncouples test data values from the test scripts that use them, and&#xD;
    provides a central point of collection and modification of the test data. This provides two key benefits: it gives&#xD;
    visibility of the test data to all test team members (allowing them to avoid potential conflicts in test data use), and&#xD;
    it provides a central point of modification for the test data when it needs to be updated.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;strong>Facilitate test state dependencies&lt;/strong>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Most tests require the system to be in a specific given state before they are executed, and should return the system to&#xD;
    a specific known state when they complete. Common dependencies involve security rights (function or data), dynamic or&#xD;
    context sensitive data (for example, system dates, order numbers, user id preferences, and so on), and data expiration&#xD;
    cycles (for instance, security passwords, product expiration dates, and so on). Some tests are highly dependent on each&#xD;
    other (for example, one test may create a unique order number, and a subsequent test may need to dispatch the same&#xD;
    order number).&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    A common solution is to use test suites to sequence dependent tests in the correct system state order. The test suites&#xD;
    can then be coupled with appropriate system recovery and setup utilities. For automated test efforts, some solutions&#xD;
    may involve using centralized storage of dynamic system data and the use of variables within the test scripts that&#xD;
    reference the centralized information.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;strong>Facilitate derived test data values&lt;/strong>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Tests sometimes need to calculate or derive appropriate data values from one or more aspects of the runtime system&#xD;
    state. This applies to test data values for both input and expected results. Consider developing utilities that&#xD;
    calculate the derived data values, simplifying test execution and eliminating potential inaccuracies introduced through&#xD;
    human error. Where possible, develop these utilities so that they can be utilized by both manual and automated test&#xD;
    efforts.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;strong>Facilitate common test navigation paths&lt;/strong>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    For test automation, you should consider isolating common navigation sequences, and implementing them using centralized&#xD;
    utility functions or test scripts. You can then reuse these common navigation sequences in many places, providing a&#xD;
    central point of modification if the navigation subsequently changes. These common navigation aids simply navigate the&#xD;
    application from one point to another; they typically do not perform any tests themselves, other than to verify their&#xD;
    start and end states.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Identify Test-Specific Design Needs&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    &lt;strong>Identify test interfaces&lt;/strong>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Consider the interfaces identified: Are there additional requirements the test effort will need included in the&#xD;
    software design, and subsequently exposed in the implementation? In some cases, additional interfaces will be required&#xD;
    specifically to support the test effort, or existing interfaces will require additional operating modes or modified&#xD;
    message signatures (changes to input and return parameters).&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    In relation to the target deployment environments (as captured in the test environment configurations) and the&#xD;
    development schedule itself, identify the constraints and dependencies placed on the test effort. These dependencies&#xD;
    may necessitate the provision of stubs to simulate elements of the environment that will not be available (or are too&#xD;
    resource prohibitive to establish for testing purposes, or to provide the opportunity for the early testing of&#xD;
    components of the partially completed system).&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;strong>Identify inbuilt test functions&lt;/strong>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Some tests are potentially valuable, but prohibitively expensive to implement as true black-box tests. Furthermore, in&#xD;
    high-reliability environments, it is important to be able to test for and isolate faults as quickly as possible to&#xD;
    enable fast resolution. In these cases, it can be useful to build tests directly into the executable software itself.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    There are different approaches that you can take to achieve this: Two of the most common include &lt;i>built-in self&#xD;
    tests&lt;/i> (where the software uses redundant processing cycles to perform self-integrity tests), and &lt;i>diagnostic&#xD;
    routines&lt;/i> (which can be performed when the software is sent a diagnostic event message, or when the system is&#xD;
    configured to run with diagnostic routines enabled).&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;strong>Identify test design constraints&lt;/strong>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Some of the design and implementation choices of the development team will either enable or inhibit the test effort.&#xD;
    While some of these choices are unavoidably necessary, there are many smaller decisions (especially in the area of&#xD;
    implementation) that have minimal impact on the development team, but significant impact on the test team.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Areas to consider include:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Use of standard, recognized communication protocols&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Use of UI implementation components that can be recognized by test automation tools&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Adhering to UI design rules including the naming of UI elements&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Consistent use of UI navigation conventions&#xD;
    &lt;/li>&#xD;
&lt;/ul>&lt;br />&#xD;
&lt;br />&#xD;
 &#xD;
&lt;h3>&#xD;
    Define Software Testability Requirements&#xD;
&lt;/h3>It is important to clearly explain to the development team the reasons why test-specific features are required to be&#xD;
built into the software. Key reasons will typically fall into one of the following areas: &#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        To enable both manual and automated tests to be implemented by providing an interface between the target test item&#xD;
        and either the manual or automated test. This is typically most relevant as a test automation concern, to help&#xD;
        overcome the limitations of test automation tools in being able to access the software application for both&#xD;
        information input and output.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        To enable built-in self-tests to be conducted by the developed software itself.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        To enable target test items to be isolated from the rest of the developed system, and then tested.&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    Test-specific features built into the software need to strike a balance between the value of a built-in test feature&#xD;
    and the effort necessary to implement and test it. Examples of built-in test features include producing audit logs,&#xD;
    self-diagnostic functions, and interfaces to interrogate the value of internal variables.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Another common use of test-specific functionality is during integration work, where there is the need to provide stubs&#xD;
    for components or subsystems that are not yet implemented or incorporated. There are two main implementation styles&#xD;
    used for stubs:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Stubs and drivers that are simply &quot;dummies&quot; with no functionality other than being able to provide a specific&#xD;
        predefined value (or values) as either input or as a return value.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Stubs and drivers that are more intelligent and can &quot;simulate&quot; or approximate more complex behavior.&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    This second style of stub also provides a powerful means of isolating components or groups of components from the rest&#xD;
    of the system, thus providing flexibility in the implementation and execution of tests. As with the earlier comment&#xD;
    about test-specific features, a balance between the value of a complex stub and the effort necessary to implement and&#xD;
    test the stub needs to be considered. Use this second style prudently for two reasons: first, it takes more resources&#xD;
    to implement, and second, it is easy to overlook the existence of the stub and forget to subsequently remove it.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Record your findings in terms of test-specific requirements on the design and implementation models directly, or using&#xD;
    one or more test interface specifications.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Define Test Infrastructure&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    &lt;strong>Test automation elements&lt;/strong>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Key requirements or features of the test automation infrastructure include:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        &lt;b>Navigation model:&lt;/b> Common approaches are round-trip, segmented, or hybrid approaches. Other alternatives&#xD;
        include using an Action-Word framework or screen navigation tables.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;b>External Data Access:&lt;/b> A method to access data externally from the test instructions&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;b>Error Reporting and Recovery:&lt;/b> Common error-handling routines and Test Suite recovery execution wrappers&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;b>Security and Access Profiles:&lt;/b> Automated Test Execution User IDs&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        The ability for the software to conduct &lt;b>self-tests&lt;/b>&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    Record your decisions as definitions in the implementation sections of the Test Automation Architecture, and your&#xD;
    process guidance in one or more Test Guidelines (or as Test Scripts, Test Suites, or test library utility routines).&#xD;
    See &lt;a class=&quot;elementLinkWithType&quot;&#xD;
    href=&quot;./../../../core.tech.common.extend-ibm/workproducts/test_automation_arch_895C43EA.html&quot;&#xD;
    guid=&quot;_ZyADgHE8Edy8Ac588DXPCQ&quot;>Artifact: Test Automation Architecture&lt;/a> for further suggestions.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;strong>Manual test elements&lt;/strong>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Key requirements or features of the manual test infrastructure include:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        &lt;b>Test Data Repository:&lt;/b> A common repository for the definition of test data&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;b>Restoration and Recovery:&lt;/b> A method to restore or recover the test environment configuration to a known state&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        To enable target test items to be &lt;b>isolated&lt;/b> from the rest of the developed system and tested.&#xD;
    &lt;/li>&#xD;
&lt;/ul></mainDescription>
</org.eclipse.epf.uma:ContentDescription>
