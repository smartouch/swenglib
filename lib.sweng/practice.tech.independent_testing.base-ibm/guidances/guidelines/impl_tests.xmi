<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:ContentDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmlns:epf="http://www.eclipse.org/epf" epf:version="1.5.1" xmlns:rmc="http://www.ibm.com/rmc" rmc:version="7.5.1" xmi:id="-Pn77qMHkfUQWHroHakKtnQ" name="new_guideline,_l80e0LJcEdyHw6xErAkVmw" guid="-Pn77qMHkfUQWHroHakKtnQ" changeDate="2010-08-31T16:05:28.875-0700" version="7.2.0">
  <mainDescription>&lt;h3>&#xD;
    Select Appropriate Implementation Technique&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    &lt;a id=&quot;ManualTestScripts&quot; name=&quot;ManualTestScripts&quot;>&lt;strong>Manual Test Scripts&lt;/strong>&lt;/a>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Many tests are best conducted manually, and you should avoid the trap of attempting to inappropriately automate tests.&#xD;
    Usability tests are an area where manual testing is in many cases a better solution than an automated one. Also, tests&#xD;
    that require validation of the accuracy and quality of the physical outputs from a software system generally require&#xD;
    manual validation. As a general heuristic, it is a good idea to begin the first tests of a particular Target Test Item&#xD;
    with a manual implementation: this approach allows the tester to learn about the target item, adapt to unexpected&#xD;
    behavior from it, and apply human judgment to determine the next appropriate action to be taken.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Sometimes, manually conducted tests will be subsequently automated and reused as part of a regression testing strategy.&#xD;
    Note, however, that it is not necessary or desirable (or even possible) to automate every test that you could otherwise&#xD;
    conduct manually. Automation brings certain advantages in speed and accuracy of test execution, visibility and&#xD;
    collation of detailed test results, and in efficiency of creating and maintaining complex tests. However, like all&#xD;
    useful tools, it is not the solution to all of your needs.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Automation comes with certain disadvantages: these basically amount to an absence of human judgment and reasoning&#xD;
    during test execution. The automation solutions currently available simply do not have the cognitive abilities that a&#xD;
    human does, and it is arguably unlikely that they ever will. During implementation of a manual test, human reasoning&#xD;
    can be applied to the observed responses of the system to stimulus. Current automated test techniques and their&#xD;
    supporting tools typically have limited ability to notice the implications of certain system behaviors, and have&#xD;
    minimal ability to infer possible problems through deductive reasoning.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;a id=&quot;ProgramTestScripts&quot; name=&quot;ProgramTestScripts&quot;>&lt;strong>Programmed Test Scripts&lt;/strong>&lt;/a>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    This is arguably the method of choice practiced by most testers who use test automation. In its purest form, this&#xD;
    practice is performed in the same manner (and using the same general principles) as software programming. As such, most&#xD;
    methods and tools used for software programming are generally applicable and useful to test automation programming.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Using either a standard software development environment (such as Microsoft Visual Studio or IBM Visual Age) or a&#xD;
    specialized test automation development environment (such as the IDE provided with IBM Rational Robot), the tester is&#xD;
    free to harness the features and power of the development environment to best effect.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The negative aspects of programming automated tests are related to the negative aspects of programming itself as a&#xD;
    general technique. For programming to be effective, some consideration should be given to appropriate design: without&#xD;
    this the implementation will likely fail. If the developed software will likely be modified by different people over&#xD;
    time (the usual situation), then some consideration must be given to adopting a common style and form to be used in&#xD;
    program development, and ensuring its correct use. Arguably the two most important concerns relate to the misuse of&#xD;
    this technique.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    First, there is a risk that a tester will become engrossed in the features of the programming environment, and spend&#xD;
    too much time crafting elegant and sophisticated solutions to problems that could be achieved by simpler means. The&#xD;
    result is that the tester wastes precious time on what are essentially programming tasks, to the detriment of time that&#xD;
    could be spent actually testing and evaluating the Target Test Items. It requires both discipline and experience to&#xD;
    avoid this pitfall.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Secondly, there is the risk that the program code used to implement the test will itself have bugs introduced through&#xD;
    human error or omission. Some of these bugs will be easy to debug and correct in the natural course of implementing the&#xD;
    automated test: others will not. Just as errors can be elusive to detect in the Target Test Item, it can be equally&#xD;
    difficult to detect errors in test automation software. Furthermore, errors may be introduced where algorithms used in&#xD;
    the automated test implementation are based on the same faulty algorithms used by the software implementation itself.&#xD;
    This results in errors going undetected, hidden by the false security of automated tests that apparently execute&#xD;
    successfully. Mitigate this risk by using different algorithms in the automated tests wherever possible.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;a id=&quot;RecordTestScripts&quot; name=&quot;RecordTestScripts&quot;>&lt;strong>Recorded or captured Test Scripts&lt;/strong>&lt;/a>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    There are a number of test automation tools that provide the ability to record or capture human interaction with a&#xD;
    software application and produce a basic Test Script. There are a number of different tool solutions for this. Most&#xD;
    tools produce a Test Script implemented in some form of a high-level, normally editable, programming language. The most&#xD;
    common designs work in one of the following ways:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Capturing the interaction with the client UI of an application based on intercepting the inputs sent from the&#xD;
        client hardware peripheral input devices (mouse, keyboard, and so forth) to the client operating system. In some&#xD;
        solutions, this is done by intercepting high-level messages exchanged between the operating system and the device&#xD;
        driver that describe the interactions in a somewhat meaningful way; in other solutions, this is done by capturing&#xD;
        low-level messages, often based at the level of time-based movements in mouse coordinates or key-up and key-down&#xD;
        events.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Intercepting the messages sent and received across the network between the client application and one or more&#xD;
        server applications. The successful interpretation of those messages relies typically on the use of standard,&#xD;
        recognized messaging protocols, such as HTTP, SQL, and so forth. Some tools also allow the capture of base&#xD;
        communications protocols such as TCP/IP, however it can be more complex to work with Test Scripts of this nature.&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    While these techniques are generally useful to include as part of your approach to automated testing, some&#xD;
    practitioners feel that these techniques have limitations. One of the main concerns is that some tools simply capture&#xD;
    application interaction and do nothing else. Without the additional inclusion of observation points that capture and&#xD;
    compare system state during subsequent script execution, the basic Test Script cannot be considered to be a&#xD;
    fully-formed test. Where this is the case, the initial recording will need to be subsequently augmented with additional&#xD;
    custom program code to implement observation points within the Test Script.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Various authors have published books and essays on this and other concerns related to using test procedure record or&#xD;
    capture as a test automation technique. To gain a more in-depth understanding of these issues, review the work&#xD;
    available on the Internet by the following authors: &lt;a href=&quot;http://www.satisfice.com/&quot; target=&quot;_blank&quot;>&lt;u>&lt;font&#xD;
    color=&quot;#0000ff&quot;>James Bach&lt;/font>&lt;/u>&lt;/a>, &lt;a href=&quot;http://www.kaner.com/&quot; target=&quot;_blank&quot;>&lt;u>Cem Kaner&lt;/u>,&lt;/a> &lt;a&#xD;
    href=&quot;http://www.testing.com/writings.html&quot; target=&quot;_blank&quot;>&lt;u>&lt;font color=&quot;#0000ff&quot;>Brian Marick&lt;/font>&lt;/u>&lt;/a> and &lt;a&#xD;
    href=&quot;http://www.io.com/~wazmo/papers/&quot; target=&quot;_blank&quot;>&lt;u>&lt;font color=&quot;#0000ff&quot;>Bret Pettichord&lt;/font>&lt;/u>&lt;/a>, and&#xD;
    the relevant content in the book &lt;i>Lessons Learned in Software Testing&lt;/i> [KAN01].&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;a id=&quot;GenerateTests&quot; name=&quot;GenerateTests&quot;>&lt;strong>Generated Tests&lt;/strong>&lt;/a>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Some of the more sophisticated test automation software enables the actual generation of various aspects of the test&#xD;
    (either the procedural aspects or the Test Data aspects of the Test Script) based on generation algorithms. This type&#xD;
    of automation can play a useful part in your test effort, but should not be considered a sufficient approach by itself.&#xD;
    The IBM&amp;reg; Rational&amp;reg; TestFactory&amp;reg; tool and the IBM&amp;reg; Rational&amp;reg; TestManager datapool generation feature are example&#xD;
    implementations of this type of technology.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Set Up Test Environment Preconditions&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    &lt;a id=&quot;ManualCheck&quot; name=&quot;ManualCheck&quot;>&lt;strong>Manual walk-through of the test&lt;/strong>&lt;/a>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Especially applicable to automated Test Scripts, it can be beneficial to initially walk-through the test manually to&#xD;
    confirm that expected prerequisites are present. During the walk-through, you should verify the integrity of the&#xD;
    environment, the software, and the test design. The walk-through is most relevant where you are using an interactive&#xD;
    recording technique, and least relevant where you are programming the Test Script. Your objective is to verify that all&#xD;
    of the elements required to implement the test successfully are present.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Where the software is known to be sufficiently stable or mature, you way elect to skip this step (you deem the risk of&#xD;
    problems occurring in the areas the manual walk-through addresses are relatively low).&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;a id=&quot;ConfirmTestOracles&quot; name=&quot;ConfirmTestOracles&quot;>&lt;strong>Identify and confirm appropriateness of Test&#xD;
    Oracles&lt;/strong>&lt;/a>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Confirm that the &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../../core.tech.common.extend-ibm/guidances/termdefinitions/test_oracle_A976C2E.html&quot;&#xD;
    guid=&quot;_GN_zUK9AEdyqIcGe5CQhlg&quot;>test oracles&lt;/a> that you plan to use are appropriate. Where they have not already been&#xD;
    identified, now is the time for you to do so.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    You should try to confirm through alternative means that the chosen Test Oracle(s) will provide accurate and reliable&#xD;
    results. For example, if you plan to validate test results using a field displayed via the application's UI that&#xD;
    indicates a database update has occurred, consider independently querying the back-end database to verify the state of&#xD;
    the corresponding records in the database. Alternatively, you might ignore the results presented in an update&#xD;
    confirmation dialog, and instead confirm the update by querying for the record through an alternative front-end&#xD;
    function or operation.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;a id=&quot;ResetEnvTools&quot; name=&quot;ResetEnvTools&quot;>&lt;strong>Reset test environment and tools&lt;/strong>&lt;/a>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Next, you should restore the environment (including the supporting tools) back to it is original state. As mentioned in&#xD;
    previous steps, this will typically involve some form of basic operating environment reset, restoration of underlying&#xD;
    databases to a known state, and so on, in addition to tasks such as loading paper into printers. While some reset tasks&#xD;
    can be performed automatically, some aspects typically require human attention.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Set the implementation options of the test-support tools, which will vary depending on the sophistication of the tool.&#xD;
    Where possible, you should consider storing the option settings for each tool so that they can be reloaded easily based&#xD;
    on one or more predetermined profiles. In the case of manual testing, it will include tasks such as partitioning a new&#xD;
    entry in a support system for logging the test results, or signing into an issue and change request logging system.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    In the case of automated test implementation tools, there may be many different settings to be considered. Failing to&#xD;
    set these options appropriately may reduce the usefulness and value of the resulting test assets.&#xD;
&lt;/p>&lt;br />&#xD;
&lt;h3>&#xD;
    Implement the Test&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    &lt;a id=&quot;NavigationActions&quot; name=&quot;NavigationActions&quot;>&lt;strong>Implement navigation actions&lt;/strong>&lt;/a>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Program, record, or generate the required navigation actions. Start by selecting your appropriate navigation method of&#xD;
    choice. For most classes of system these days, a mouse or other pointing device is the preferred and primary medium for&#xD;
    navigation. For example, the pointing and scribing device used with a Personal Digital Assistants (PDA) is conceptually&#xD;
    equivalent to a mouse.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The secondary navigation means is generally that of keyboard interaction. In most cases, navigation will be made up of&#xD;
    a combination of mouse-driven and keyboard-driven actions.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    In some cases, you will need to consider voice-activated, light, visual, and other forms of recognition. These can be&#xD;
    more troublesome to automate tests against, and may require the addition of special test-interface extensions to the&#xD;
    application to allow audio and visual elements to be loaded and processed from file (rather than captured dynamically).&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    In some situations, you may want to (or need to) perform the same test using multiple navigation methods. There are&#xD;
    different approaches that you can take to achieve this. For example:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Automate all of the tests using one method, and manually perform all or some subset of the tests using others&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Separate the navigation aspects of the tests from the Test Data that characterize the specific test by providing&#xD;
        and building a logical navigation interface that allows either method to be selected to drive the test&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Simply mix and match navigation methods&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    &lt;a id=&quot;ObservationPoint&quot; name=&quot;ObservationPoint&quot;>&lt;strong>Implement observation points&lt;/strong>&lt;/a>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    At each point in the Test Script where an observation should be taken, use the appropriate Test Oracle to capture the&#xD;
    desired information. In many cases, the information gained from the observation point will need to be recorded and&#xD;
    retained to be referenced during subsequent control points.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Where this is an automated test, decide how the observed information should be reported from the Test Script. In most&#xD;
    cases, it is usually appropriate simply to record the observation in a central Test Log relative to its delta (time&#xD;
    from the start of the Test Script). In other cases, specific observations might be output separately to a spreadsheet&#xD;
    or data file for more sophisticated uses.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;a id=&quot;ControlPoint&quot; name=&quot;ControlPoint&quot;>&lt;strong>Implement control points&lt;/strong>&lt;/a>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    At each point in the Test Script where a control decision should be taken, obtain and assess the appropriate&#xD;
    information to determine the correct branch for the flow of control to follow. The data retrieved form prior&#xD;
    observation points is usually input to control points.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Where a control point occurs, and a decision made about the next action in the flow-of-control, record the input values&#xD;
    to the control point, and the resulting flow that is selected in the Test Log.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;a id=&quot;ResolveImplementErrors&quot; name=&quot;ResolveImplementErrors&quot;>&lt;strong>Resolve errors in the test&#xD;
    implementation&lt;/strong>&lt;/a>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    During test implementation, you will likely introduce errors in the test implementation itself. Those errors may even&#xD;
    be the result of things that you have omitted from the test implementation, or they may be related to things that you&#xD;
    have failed to consider in the test environment. These errors will need to be resolved before the test can be&#xD;
    considered completely implemented. Identify each error that you encounter, and work through addressing them.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    In the case of test automation that uses a programming language, this might include compilation errors due to&#xD;
    undeclared variables and functions, or invalid use of those functions. Work your way through the error messages&#xD;
    displayed by the compiler (or any other sources of error messages) until the Test Script is free of syntactical and&#xD;
    other basic implementation errors.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    During subsequent execution of the test, other errors in the test implementation might be found. Initially, these may&#xD;
    appear to be failures in the target test item: you need to be diligent when analyzing test failures, so that you&#xD;
    confirm that the failures are actually in the target test item, and not in some aspect of the test implementation.&#xD;
&lt;/p></mainDescription>
</org.eclipse.epf.uma:ContentDescription>
