<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:ContentDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmlns:epf="http://www.eclipse.org/epf" epf:version="1.5.1" xmlns:rmc="http://www.ibm.com/rmc" rmc:version="7.5.1" xmi:id="-QyvBTnOW7NdvWiIxr9B_5w" name="how_to_adopt_structured_testing,_5bS8YNUcEdySMfcrDUmpxg" guid="-QyvBTnOW7NdvWiIxr9B_5w" changeDate="2009-02-22T22:35:59.671-0800" version="7.2.0">
  <mainDescription>&lt;p>&#xD;
    Testing focuses primarily on evaluating or assessing product quality. These are the main activities:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Find and document defects in software quality.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Advise on the perceived software quality.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Validate and prove the assumptions made in design and requirement specifications through demonstration.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Validate that the software product works as designed.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Validate that the requirements are implemented appropriately.&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    Testing is to find and expose weaknesses in the software product. To get the biggest benefit, you need a different&#xD;
    philosophy than what's used in the rest of the development cycle. A somewhat subtle difference is that&amp;nbsp;during most&#xD;
    of the development the&amp;nbsp;focus is&amp;nbsp;on completeness, whereas testing focuses on incompleteness. A good test&#xD;
    effort is driven by questions such as &quot;How could this software 'break,' and&amp;nbsp;in&amp;nbsp;what possible situations could&#xD;
    this software fail to work predictably?&quot;&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Testing challenges the assumptions, risks, and uncertainty inherent in the work of developing a product and addresses&#xD;
    those concerns by using concrete demonstrations and impartial evaluations. You need to avoid two potential extremes:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        An approach that does not suitably or effectively challenge the software and expose its inherent problems or&#xD;
        weaknesses&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        An approach that is inappropriately negative (because you might find it impossible to consider the software product&#xD;
        of acceptable quality and could alienate the rest of the development team from the test effort)&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    Information presented in various surveys and essays states that software testing accounts for 30 to 50 percent of total&#xD;
    software development costs.&amp;nbsp; It is somewhat surprising that most people believe computer software is not&#xD;
    well-tested before it is delivered. This contradiction is rooted in a few key issues:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Testing software is very difficult. How do you quantify the different ways in which a given program can behave?&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Typically, testing is done without a clear methodology, thus creating results that vary from project to project and&#xD;
        from organization to organization. Success is primarily a factor of the quality and skills of the individuals.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Productivity tools are used insufficiently, which makes the laborious aspects of testing unmanageable. In addition&#xD;
        to the lack of automated test execution, many test efforts are conducted without tools that let you effectively&#xD;
        manage extensive test data and test results. Flexibility of use and complexity of software make complete testing an&#xD;
        impossible goal. Using a well-conceived methodology and state-of-the-art tools can improve both the productivity&#xD;
        and effectiveness of software testing.&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h3>&#xD;
    How to adopt this practice&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Here's one possible scenario for adopting this practice. You may want to add, change, or&amp;nbsp;remove steps to design an&#xD;
    adoption roadmap more suitable to your environment. Hiring a consultant who is experienced in&amp;nbsp;this area&amp;nbsp;will&#xD;
    also speed your adoption of the practice and help avoid common pitfalls.&#xD;
&lt;/p>&#xD;
&lt;ol>&#xD;
    &lt;li>&#xD;
        Educate the team about the&amp;nbsp;Independent Testing practice. Courses and presentations are available (see the&#xD;
        Additional Information section in &lt;a class=&quot;elementLink&quot;&#xD;
        href=&quot;./../../../practice.tech.independent_testing.base-ibm/guidances/practices/independent_testing_30ABFB15.html&quot;&#xD;
        guid=&quot;_fnn70CFAEd2KZfP7K7AmSg&quot;>Independent Testing&lt;/a>).&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Have the team review the material in this practice.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Perform a gap analysis between your current practices and the proposed one. Focus on problem areas. Try to&#xD;
        distinguish between real differences and just terminology mismatches.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Identify extension points and extend this practice to reflect any important requirements and constraints in your&#xD;
        organization.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Reuse the current elements that reflect your specific environment, such as templates and examples, by attaching&#xD;
        them to the proposed practice.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Identify and prepare to collect the information or metrics that will tell you how well you're adopting this&#xD;
        practice. Make sure that the data and metrics are easy to collect. Highly accurate metrics that are difficult to&#xD;
        collect are often abandoned, thus they provide no value. Coarser measurements that are easy to collect usually&#xD;
        provide sufficient information, and it's more likely that they'll continue to be collected.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Develop an adoption plan with specific goals for each step. An iterative, incremental approach works best. Try to&#xD;
        tackle the problem points identified earlier.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Select a project where you will start applying the new practice. This pilot project should be sufficiently visible&#xD;
        and risky to properly adopt this practice.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Evaluate your adoption based on the objectives and metrics that you defined.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Make adjustments based on your evaluation. Eliminate tools or tool features that don't prove effective, and&#xD;
        increase practices that are efficient and improve quality.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Determine the next step in adoption.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Continue to extend or modify this practice to reflect how your team and organization is performing this new process&#xD;
        and what the next increment of adoption should be for your team.&#xD;
    &lt;/li>&#xD;
&lt;/ol>&#xD;
&lt;h3>&#xD;
    How to tailor this practice&amp;nbsp;&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    This section presents the most important aspects that you need to consider when you tailor this practice to meet your&#xD;
    specific environment.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    Decide how to use work products&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Make a decision about what work products are to be&amp;nbsp;used and how they are to be used.&amp;nbsp; It is also important to&#xD;
    tailor each work product to be used to fit the needs of the project.&amp;nbsp;&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The table that follows specifies which testing work products are recommended and which are considered optional (can be&#xD;
    used&amp;nbsp;in certain cases). For additional tailoring considerations, see the Tailoring section of the work product&#xD;
    description page.&#xD;
&lt;/p>&#xD;
&lt;div>&#xD;
    &lt;table&#xD;
    style=&quot;BORDER-BOTTOM: rgb(128,128,128) 1px solid; BORDER-LEFT: rgb(128,128,128) 1px solid; BORDER-TOP: rgb(128,128,128) 1px solid; BORDER-RIGHT: rgb(128,128,128) 1px solid&quot;&#xD;
     border=&quot;1&quot; cellspacing=&quot;0&quot; bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot; cellpadding=&quot;4&quot; width=&quot;100%&quot;>&#xD;
        &lt;tbody>&#xD;
            &lt;tr>&#xD;
                &lt;th width=&quot;20%&quot; scope=&quot;col&quot; align=&quot;left&quot;>&#xD;
                    Work product&#xD;
                &lt;/th>&#xD;
                &lt;th width=&quot;40%&quot; scope=&quot;col&quot; align=&quot;left&quot;>&#xD;
                    Purpose&#xD;
                &lt;/th>&#xD;
                &lt;th width=&quot;40%&quot; scope=&quot;col&quot; align=&quot;left&quot;>&#xD;
                    Tailoring (optional, recommended)&#xD;
                &lt;/th>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;20%&quot;>&#xD;
                    &lt;a class=&quot;elementLink&quot;&#xD;
                    href=&quot;./../../../core.tech.common.extend_supp-ibm/workproducts/test_evaluation_summary_7C2958B.html&quot;&#xD;
                    guid=&quot;_iD7vkHFfEdy8Ac588DXPCQ&quot;>Test Evaluation Summary&lt;/a>&amp;nbsp;&#xD;
                &lt;/td>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;40%&quot;>&#xD;
                    Summarizes the test results for use primarily by the management team and other stakeholders external to&#xD;
                    the test team.&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;40%&quot;>&#xD;
                    Recommended for most projects.&lt;br />&#xD;
                    &lt;br />&#xD;
                    Where the project culture is relatively information, it may be appropriate simply to record test&#xD;
                    results and not create formal evaluation summaries. In other cases, Test Evaluation Summaries can be&#xD;
                    included as a section within other assessment work products, such as the&amp;nbsp;Iteration Assessment or&#xD;
                    Review Record.&amp;nbsp;&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;20%&quot;>&#xD;
                    &lt;a class=&quot;elementLink&quot;&#xD;
                    href=&quot;./../../../core.tech.common.extend_supp-ibm/workproducts/test_findings_565B9E24.html&quot;&#xD;
                    guid=&quot;_DwNAQHE8Edy8Ac588DXPCQ&quot;>Test Findings&lt;/a>&#xD;
                &lt;/td>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;40%&quot;>&#xD;
                    This work product is the analyzed result determined from the raw data in one or more test logs.&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;40%&quot;>&#xD;
                    Recommended. Most test teams retain some form of reasonably detailed record of the results of testing.&#xD;
                    Manual testing results are usually recorded directly here and combined with the distilled test logs&#xD;
                    from automated tests.&lt;br />&#xD;
                    &lt;br />&#xD;
                    In some cases, test teams will go directly from the test logs to producing the Test Evaluation Summary.&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;20%&quot;>&#xD;
                    &lt;a class=&quot;elementLink&quot;&#xD;
                    href=&quot;./../../../core.tech.common.extend_supp/workproducts/test_log_CBA2FDF4.html&quot;&#xD;
                    guid=&quot;_0ZlSsMlgEdmt3adZL5Dmdw&quot;>Test Log&lt;/a>&amp;nbsp;&#xD;
                &lt;/td>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;40%&quot;>&#xD;
                    &lt;p>&#xD;
                        The raw data output during test execution, typically produced by automated tests.&#xD;
                    &lt;/p>&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;40%&quot;>&#xD;
                    &lt;p>&#xD;
                        Optional.&#xD;
                    &lt;/p>&#xD;
                    &lt;p>&#xD;
                        Many projects that perform automated testing will have some form of test log. Where projects differ&#xD;
                        is whether the test logs are retained or discarded after the test results have been determined.&#xD;
                    &lt;/p>&#xD;
                    &lt;p>&#xD;
                        You might retain test logs if you need to satisfy certain audit requirements, if you want to&#xD;
                        analyze how the raw test output data changes over time, or if you are uncertain at the outset of&#xD;
                        all the analysis that you may be required to provide.&#xD;
                    &lt;/p>&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;20%&quot;>&#xD;
                    &lt;a class=&quot;elementLink&quot;&#xD;
                    href=&quot;./../../../core.tech.common.extend_supp-ibm/workproducts/test_suite_DA2E3AF2.html&quot;&#xD;
                    guid=&quot;_roUk0HE8Edy8Ac588DXPCQ&quot;>Test Suite&lt;/a>&#xD;
                &lt;/td>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;40%&quot;>&#xD;
                    Used to group individual related tests (test scripts) together in meaningful subsets.&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;40%&quot;>&#xD;
                    Recommended for most projects.&lt;br />&#xD;
                    &lt;br />&#xD;
                    Also required to define any test script execution sequences that are required for tests to work&#xD;
                    correctly.&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;20%&quot;>&#xD;
                    &lt;a class=&quot;elementLink&quot;&#xD;
                    href=&quot;./../../../core.tech.common.extend_supp-ibm/workproducts/test_ideas_list_195666E2.html&quot;&#xD;
                    guid=&quot;_7ukFEHE7Edy8Ac588DXPCQ&quot;>Test Ideas List&lt;/a>&amp;nbsp;&#xD;
                &lt;/td>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;40%&quot;>&#xD;
                    This is an enumerated list of tests to consider conducting (often partially formed).&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;40%&quot;>&#xD;
                    Recommended for most projects.&lt;br />&#xD;
                    &lt;br />&#xD;
                    In some cases these lists will be informally defined and discarded after the test scripts or test cases&#xD;
                    have been defined from them.&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;20%&quot;>&#xD;
                    &lt;a class=&quot;elementLink&quot;&#xD;
                    href=&quot;./../../../core.tech.common.extend_supp-ibm/workproducts/test_strategy_AB15461A.html&quot;&#xD;
                    guid=&quot;_nbNrMHE8Edy8Ac588DXPCQ&quot;>Test Strategy&lt;/a>&#xD;
                &lt;/td>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;40%&quot;>&#xD;
                    Defines the strategic plan for how the test effort will be conducted against one or more aspects of the&#xD;
                    target system.&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;40%&quot;>&#xD;
                    Recommended for most projects.&lt;br />&#xD;
                    &lt;br />&#xD;
                    A single test strategy per project or per phase within a project is recommended in most cases.&#xD;
                    Optionally, you might reuse existing strategies where appropriate, or you might further subdivide the&#xD;
                    test strategies based on the type of testing that you are conducting.&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;20%&quot;>&#xD;
                    &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
                    href=&quot;./../../../core.tech.common.extend_supp-ibm/workproducts/test_plan_7503019A.html&quot;&#xD;
                    guid=&quot;_yiMRwHFfEdy8Ac588DXPCQ&quot;>Iteration Test Plan&lt;/a>&#xD;
                &lt;/td>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;40%&quot;>&#xD;
                    Defines finer-grained testing goals, objectives, motivations, approach, resources, schedule and work&#xD;
                    products that govern an iteration.&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;40%&quot;>&#xD;
                    Recommended for most projects.&lt;br />&#xD;
                    &lt;br />&#xD;
                    A separate test plan for each iteration is best to define the specific, fine-grained test strategy.&#xD;
                    Optionally, you can include the test plan as a section within the iteration plan.&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;20%&quot;>&#xD;
                    &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
                    href=&quot;./../../../core.tech.common.extend_supp-ibm/workproducts/test_plan_7503019A.html&quot;&#xD;
                    guid=&quot;_yiMRwHFfEdy8Ac588DXPCQ&quot;>Master Test Plan&lt;/a>&#xD;
                &lt;/td>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;40%&quot;>&#xD;
                    Defines high-level testing goals, objectives, approaches, resources, schedule, and work products that&#xD;
                    govern a phase or the entire lifecycle.&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;40%&quot;>&#xD;
                    Optional. Useful for most projects.&lt;br />&#xD;
                    &lt;br />&#xD;
                    A Master Test Plan defines the high-level strategy for the test effort over large parts of the software&#xD;
                    development lifecycle. Optionally, you can include the Test Plan as a section within a Software&#xD;
                    Development Plan.&lt;br />&#xD;
                    &lt;br />&#xD;
                    Consider whether to maintain a Master Test Plan in addition to the Iteration Test Plans. The Master&#xD;
                    Test Plan covers mainly logistical and process information that typically relates to the entire project&#xD;
                    lifecycle; it is unlikely to change between iterations.&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;20%&quot;>&#xD;
                    &lt;a class=&quot;elementLink&quot;&#xD;
                    href=&quot;./../../../core.tech.common.extend_supp/workproducts/test_script_39A30BA2.html&quot;&#xD;
                    guid=&quot;_0ZfMEMlgEdmt3adZL5Dmdw&quot;>Test Script&lt;/a>, &lt;a class=&quot;elementLink&quot;&#xD;
                    href=&quot;./../../../core.tech.common.extend_supp-ibm/workproducts/test_data_5B6611FC.html&quot;&#xD;
                    guid=&quot;_3pyoEHE7Edy8Ac588DXPCQ&quot;>Test Data&lt;/a>&#xD;
                &lt;/td>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;40%&quot;>&#xD;
                    The test scripts and test data are the realization or implementation of the test, where the test script&#xD;
                    embodies the procedural aspects and the test data embodies the defining characteristics.&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;40%&quot;>&#xD;
                    Recommended for most projects.&lt;br />&#xD;
                    &lt;br />&#xD;
                    Where projects differ is how formally these work products are treated. In some cases, these are&#xD;
                    informal and transitory, and the test team is judged based on other criteria. In other cases --&#xD;
                    especially with automated tests -- the test scripts and associated test data (or some subset thereof)&#xD;
                    are regarded as major deliverables of the test effort.&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;20%&quot;>&#xD;
                    &lt;a class=&quot;elementLink&quot;&#xD;
                    href=&quot;./../../../core.tech.common.extend_supp/workproducts/test_case_335C5DEA.html&quot;&#xD;
                    guid=&quot;_0ZS-0MlgEdmt3adZL5Dmdw&quot;>Test Case&lt;/a>&#xD;
                &lt;/td>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;40%&quot;>&#xD;
                    &lt;p>&#xD;
                        Defines a specific set of test inputs, execution conditions, and expected results.&#xD;
                    &lt;/p>&#xD;
                    &lt;p>&#xD;
                        Documenting test cases allows them to be reviewed for completeness and correctness, and considered&#xD;
                        before implementation effort is planned and expended.&#xD;
                    &lt;/p>&#xD;
                    &lt;p>&#xD;
                        This is most useful where the input, execution conditions, and expected results are particularly&#xD;
                        complex.&#xD;
                    &lt;/p>&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;40%&quot;>&#xD;
                    &lt;p>&#xD;
                        On most projects, were the conditions required to conduct a specific test are complex or extensive,&#xD;
                        it is advisable to define test cases. You will also need to document test cases where they are a&#xD;
                        contractually required deliverable.&#xD;
                    &lt;/p>&#xD;
                    &lt;p>&#xD;
                        In most other cases, it is more useful to maintain the Test Ideas List and the Implemented Test&#xD;
                        Scripts List rather than detailed descriptions of test cases.&#xD;
                    &lt;/p>&#xD;
                    &lt;p>&#xD;
                        Some projects will simply outline test cases at a high level and defer details to the test scripts.&#xD;
                        Another style commonly used is to document the test case information as comments within the test&#xD;
                        scripts.&#xD;
                    &lt;/p>&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;20%&quot;>&#xD;
                    Workload Specification&#xD;
                &lt;/td>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;40%&quot;>&#xD;
                    &lt;p>&#xD;
                        A specialized type of test case. Used to define a representative workload to allow quality risks&#xD;
                        associated with the system operating under load to be assessed.&#xD;
                    &lt;/p>&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;40%&quot;>&#xD;
                    &lt;p>&#xD;
                        Recommended for most systems, especially those where system performance under load must be&#xD;
                        evaluated or where there are other significant quality risks associated with system operation under&#xD;
                        load.&#xD;
                    &lt;/p>&#xD;
                    &lt;p>&#xD;
                        Not usually required for systems that will be deployed on a standalone target system.&#xD;
                    &lt;/p>&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;20%&quot;>&#xD;
                    &lt;p>&#xD;
                        Testability classes&amp;nbsp;in the Design model&#xD;
                    &lt;/p>&#xD;
                    &lt;p>&#xD;
                        Testability elements in the Implementation model&#xD;
                    &lt;/p>&#xD;
                &lt;/td>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;40%&quot;>&#xD;
                    &lt;p>&#xD;
                        If the project has to develop significant additional specialized behavior to accommodate and&#xD;
                        support testing, these concerns are represented by the inclusion of testability classes in the&#xD;
                        Design model and the testability elements in the Implementation model.&#xD;
                    &lt;/p>&#xD;
                &lt;/td>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;40%&quot;>&#xD;
                    &lt;p>&#xD;
                        Where required.&#xD;
                    &lt;/p>&#xD;
                    &lt;p>&#xD;
                        Stubs are a common category of test classes and test components.&#xD;
                    &lt;/p>&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;20%&quot;>&#xD;
                    &lt;a class=&quot;elementLink&quot;&#xD;
                    href=&quot;./../../../core.tech.common.extend_supp-ibm/workproducts/test_architecture_2AEFCE20.html&quot;&#xD;
                    guid=&quot;_QGQ-AHE8Edy8Ac588DXPCQ&quot;>Test Architecture&lt;/a>&#xD;
                &lt;/td>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;40%&quot;>&#xD;
                    &lt;p>&#xD;
                        Provides an architectural overview of the test automation system by using several different&#xD;
                        architectural views to depict different aspects of the system.&#xD;
                    &lt;/p>&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;40%&quot;>&#xD;
                    &lt;p>&#xD;
                        Optional.&#xD;
                    &lt;/p>&#xD;
                    &lt;p>&#xD;
                        Recommended on projects where the test architecture is relatively complex, when a large number of&#xD;
                        staff members will be collaborating on building automated tests, or when the test automation system&#xD;
                        is expected to be maintained over a long period of time.&#xD;
                    &lt;/p>&#xD;
                    &lt;p>&#xD;
                        In some cases, this might simply be a whiteboard diagram that is recorded centrally for interested&#xD;
                        parties to consult.&#xD;
                    &lt;/p>&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;20%&quot;>&#xD;
                    &lt;a class=&quot;elementLink&quot;&#xD;
                    href=&quot;./../../../core.tech.common.extend_supp-ibm/workproducts/test_interface_spec_A9177D18.html&quot;&#xD;
                    guid=&quot;_jFAf8HE8Edy8Ac588DXPCQ&quot;>Test Interface Specification&lt;/a>&#xD;
                &lt;/td>&#xD;
                &lt;td valign=&quot;top&quot; width=&quot;40%&quot;>&#xD;
                    &lt;p>&#xD;
                        Defines a required set of behaviors by a classifier (specifically, a class, subsystem or component)&#xD;
                        for the purposes of testing (testability). Common types include test access, stubbed behavior,&#xD;
                        diagnostic logging, and test oracles.&#xD;
                    &lt;/p>&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;40%&quot;>&#xD;
                    &lt;p>&#xD;
                        Optional.&#xD;
                    &lt;/p>&#xD;
                    &lt;p>&#xD;
                        On many projects, there is either sufficient accessibility for test in the visible operations on&#xD;
                        classes, user interfaces etc.&#xD;
                    &lt;/p>&#xD;
                    &lt;p>&#xD;
                        Common reasons to create test interface specifications include UI extensions to allow GUI test&#xD;
                        tools to interact with the tool and diagnostic message logging routines, especially for batch&#xD;
                        processes.&#xD;
                    &lt;/p>&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
        &lt;/tbody>&#xD;
    &lt;/table>&#xD;
&lt;/div>&#xD;
&lt;h4>&#xD;
    &lt;br />&#xD;
    Decide how to review work products&#xD;
&lt;/h4>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        &lt;b>Defects:&lt;/b> The treatment of Defect reviews is very much dependent on context. However, they are generally&#xD;
        treated as &lt;i>Informal&lt;/i>, &lt;i>Formal-Internal&lt;/i>, or &lt;i>Formal-External&lt;/i>. This review process is often&#xD;
        enforced or at least assisted by workflow management in a defect-tracking system. In general, the level of review&#xD;
        formality often relates to the perceived severity or impact of the defect, but factors such as project culture and&#xD;
        level of ceremony often have an effect on the choice of review handling methods. &#xD;
        &lt;p>&#xD;
            In some cases, you may need to consider separating the handling of defects (also known as symptoms or failures)&#xD;
            from faults: the actual source of the error. For small projects, you can typically manage by tracking only the&#xD;
            defects and implicitly handle the faults. However, as the system grows in complexity, it may be beneficial to&#xD;
            separate the management of defects from faults. For example, several defects may be caused by the same fault.&#xD;
            If a fault is fixed, it's necessary to find the reported defects and inform those users who submitted the&#xD;
            defects, which is only possible if defects and faults can be identified separately.&#xD;
        &lt;/p>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;b>Test plan and test strategy:&lt;/b> In any project where the testing is nontrivial, you will need some form of test&#xD;
        plan or strategy. Generally you'll need a test plan for each iteration and some form of governing test strategy.&#xD;
        Optionally, you might create and maintain a Master Test Plan. In many cases, these work products are reviewed as&#xD;
        Informal; that is, they are reviewed but not formally approved. Where testing visibility is important to&#xD;
        stakeholders external to the test team, it should be treated as Formal-Internal or even Formal-External.&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        &lt;b>Test scripts:&lt;/b> Test scripts are usually treated as &lt;b>Informal&lt;/b>; that is, they are approved by someone&#xD;
        within the test team. If the test scripts are to be used by many testers and shared or reused for many different&#xD;
        tests, they should be treated as Formal-Internal.&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        &lt;b>Test cases:&lt;/b> Test cases are created by the test team and, depending on context, are typically reviewed using&#xD;
        either an Informal process or simply not reviewed as all. Where appropriate, test cases might be approved by other&#xD;
        team members, in which case they can be treated as Formal-Internal, or they can be reviewed by external&#xD;
        stakeholders, in which case they would be Formal-External. &#xD;
        &lt;p>&#xD;
            As a general heuristic, we recommend that you plan to formally review only the test cases that it is necessary&#xD;
            to review, which generally will be limited to a small subset that represents the most significant test cases.&#xD;
            For example, where a customer wants to validate a product before it is released, a subset of the test cases&#xD;
            could be selected as the basis for that validation. These test cases should be treated as Formal-External.&#xD;
        &lt;/p>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;b>Test work products in design and implementation.&lt;/b> &lt;i>Testability classes&lt;/i> are found in the Design model,&#xD;
        and &lt;i>testability elements&lt;/i> are in the Implementation model. There are also two other related work products&#xD;
        (although not specific to tests): &lt;i>packages&lt;/i> in the Design model, and &lt;i>subsystems&lt;/i> in the Implementation&#xD;
        model. &#xD;
        &lt;p>&#xD;
            These work products are design and implementation work products. However, they're created for the purpose of&#xD;
            supporting testing functionality in the software. The natural place to keep them is with the design and&#xD;
            implementation work products. Remember to name or otherwise label them in such a way that they are clearly&#xD;
            separated from the design and implementation of the core system. Review these work products by following the&#xD;
            review procedures for design and implementation work products.&#xD;
        &lt;/p>&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h4>&#xD;
    Decide on approval criteria&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    As you enter each iteration, strive to clearly define up front how the test effort will be judged to have been&#xD;
    sufficient, and on what basis that judgment will be measured. Do this by discussion with the individual or group&#xD;
    responsible for making the approval decision.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    These are examples of ways to handle iteration approval:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        The project management team approves the iteration and assesses the testing effort by reviewing the test evaluation&#xD;
        summaries.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        The customer approves the iteration by reviewing the test evaluation summaries.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        The customer approves the iteration based on the results of a demonstration that exercises a certain subset of the&#xD;
        total tests. This subset of tests should be defined and agreed beforehand, preferably early in the iteration. These&#xD;
        tests are treated as Formal-External and are often referred to as &lt;i>acceptance tests&lt;/i>.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        The customer approves the system quality by conducting their own independent tests, instead. Again, the nature of&#xD;
        these tests should be clearly defined and agreed beforehand, preferably early in the iteration. These tests are&#xD;
        also treated as &lt;b>Formal-External&lt;/b> and are often referred to as &lt;i>acceptance tests.&lt;/i>&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    This is an important decision. You cannot reach a goal if you don't know what it is.&#xD;
&lt;/p></mainDescription>
</org.eclipse.epf.uma:ContentDescription>
