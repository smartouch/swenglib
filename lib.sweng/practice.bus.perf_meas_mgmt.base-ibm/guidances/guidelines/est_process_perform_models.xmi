<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:ContentDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmlns:rmc="http://www.ibm.com/rmc" rmc:version="7.5.1" xmlns:epf="http://www.eclipse.org/epf" epf:version="1.5.1" xmi:id="-Yb6orCW3H5MP2ZUREsILPw" name="new_guideline,_9VYWEFouEeCJraKgJ7stRA" guid="-Yb6orCW3H5MP2ZUREsILPw" changeDate="2011-07-12T13:25:21.296-0700" version="7.5.1">
  <mainDescription>&lt;p>&#xD;
    Process performance models help the organization understand how their processes have performed in the past, and provide&#xD;
    an expected range of future process performance based on that historical information. These models are calibrated using&#xD;
    past project process and product metrics in order to predict the results future projects will achieve by following the&#xD;
    same process.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Organizations establish process performance models in order to:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        assess the potential return on investment/ business value of software capability improvement activities;&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        provide insight into the effect of implemented process changes on process capability and performance;&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        understand how projects should select and tailor organizational processes for optimum performance;&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        provide insight into how project variables impact process and product performance;&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        estimate&amp;nbsp;progress toward achieving objectives that cannot be measured until a future phase of the&amp;nbsp;project&#xD;
        lifecycle;&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        enable confidence in estimation activities and meeting project objectives&amp;nbsp;(within predicted performance&#xD;
        ranges)&amp;nbsp;through consistent statistical analysis of processes;&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        enable &quot;what-if&quot; analysis and/or trade-off analysis for project planning and taking corrective actions during the&#xD;
        project lifecycle;&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h3>&#xD;
    Establish and maintain process performance models&#xD;
&lt;/h3>&#xD;
&lt;h4>&#xD;
    Identify business objectives and critical processes&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    In order to determine which process performance models&amp;nbsp;to establish you&amp;nbsp;must&amp;nbsp;first confirm your business&#xD;
    objectives. This step is typically performed when you are setting up a Performance Measurement System and&#xD;
    re-confirmed&amp;nbsp;as part of its ongoing management. Identify the relationships between those measurable objectives&#xD;
    (e.g. improve quality, improve productivity)&amp;nbsp;and their&amp;nbsp;associated critical processes and subprocesses. These&#xD;
    vital processes are candidates to statistically manage and control with process performance models.&amp;nbsp;Narrow down&#xD;
    the list of potential candidates to only&amp;nbsp;those subprocesses that drive key business objectives and for which there&#xD;
    is data available to establish baselines and develop models.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    For example, if a key business objective is to Improve Quality,&amp;nbsp;a&amp;nbsp;process performance objective may be to&#xD;
    reduce defect density to less than .5 defects per KLOC (thousand lines of code). You may also attach qualifiers for&#xD;
    that performance objective to prevent suboptimizing in&amp;nbsp;another area (e.g. you want to reduce defect density&#xD;
    without increasing costs by a certain amount). Next, identify the processes that drive that performance objective.&#xD;
    Processes like functional testing, reviews, and requirements development all impact defect density. These processes can&#xD;
    be further broken down into sub-processes like&amp;nbsp;integration testing, walkthroughs, and requirements analysis. These&#xD;
    sub-processes are candidates for statistical management and control.&amp;nbsp;&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    Identify prediction outcomes&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Identify what outcomes you will predict within projects across the organization. These are&amp;nbsp;your outcome&#xD;
    measures.&amp;nbsp; For example, if you want to reduce defect density, you should predict your project defect arrival and&#xD;
    removal trends (control measures)&amp;nbsp;in each phase&amp;nbsp;of the lifecycle. These measurements&amp;nbsp;are indicators of&#xD;
    project quality. Outcomes&amp;nbsp;help you&amp;nbsp;identify when corrective actions are required. Outcome and control&#xD;
    measures are typically identified when you are setting up your Performance Measurement System.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    Identify controllable factors that impact outcomes&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Projects have direct or indirect influence over factors that can affect project outcomes. These variables include&#xD;
    controllable factors such as staffing, skills and expertise, selected tools, and technologies. Projects can adjust&#xD;
    these variables to improve their outcomes. You should also identify uncontrollable factors like contract-related&#xD;
    constraints and&amp;nbsp;regulations. These variables may be unchangeable on a particular project, but not affect future&#xD;
    projects.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    Collect data&amp;nbsp;and assess its&amp;nbsp;integrity&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Harvest project measurement data as part of your Performance Measurement system so that it can be analyzed. Confirm the&#xD;
    completeness, accuracy and integrity of your measurement data to&amp;nbsp;avoid errors in decision making and&#xD;
    the&amp;nbsp;implementation of&amp;nbsp;process changes that are inappropriate or unnecessary.&amp;nbsp; Typical causes of bad&#xD;
    measurement data include data entry errors, missing data, inconsistent metric definitions, no management support for&#xD;
    the priority of data collection, and&amp;nbsp;inefficient data collection mechanisms.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    Identify data types of all outcomes and variables&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Determine the types of data&amp;nbsp;you collect (e.g.&amp;nbsp;ratio, nominal, ordinal). These types will impact&#xD;
    the&amp;nbsp;selection of&amp;nbsp;analysis techniques&amp;nbsp;to perform.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    Establish baselines&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Project performance baselines are a measurement of past and current history for all identified factors.&#xD;
    Baselines&amp;nbsp;are used to monitor improvement based on process changes and changes in project variables.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    Select appropriate analytical models&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Analysis&amp;nbsp;techniques typically used in process performance modeling&amp;nbsp;include statistical modeling, Monte Carlo&#xD;
    simulation, probabilistic modeling, and many others. By knowing the data type of your variables and your outcomes you&#xD;
    can identify the appropriate analysis technique. For example, Monte Carlo simulations allow modeling of variables that&#xD;
    are uncertain (e.g. a range of values instead of a single value). This technique is useful when you want to analyze&#xD;
    simultaneous effects of many uncertain variables, such as&amp;nbsp;in risk&amp;nbsp;management&amp;nbsp;or schedule estimation&#xD;
    (best case/ worst case).&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    Create Predictions with both confidence and prediction intervals&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Create predictions of outcomes to enable decision making. Confidence intervals are a statistical range of behavior of&#xD;
    an average value computed from a sample of future data points. Prediction intervals are a statistical range of behavior&#xD;
    of individual future data points.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    Statistically manage sub-processes with PPMs&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    With process performance models in place you can begin to statistically manage your subprocesses to help predict where&#xD;
    process performance should be compared to its actuals. If performance is outside of predictions then perform additional&#xD;
    analysis to determine the cause.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Accuracy of predictions depends on:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        the quality, stability, and tailorability of the process definition&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        consistency of project compliance&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        relevance and suitability of the the selected process performance model/ analysis technique&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h4>&#xD;
    Take Action Based on predictions&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Investigate unacceptable ranges of values for given outcomes in order to plan corrective actions and process&#xD;
    improvements. You may need to recreate your process performance models based on unidentified project variables, or&#xD;
    perform some trade-off analysis for process improvements (e.g. improving defect detection processes may make projects&#xD;
    more expensive).&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    Calibrate process performance models&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Validate and maintain your process performance models. Confirm that each model is providing practical value and that&#xD;
    the analysis techniques used are appropriate for the associated data types. Confirm that your models are accurately&#xD;
    predicting performance. Recalibrate your model as needed.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Process performance models may not be very accurate in the beginning. The more project data harvested and fed into the&#xD;
    model over time, the better your process performance predictions will be.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    Prerequisites&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    In order to support process performance modeling, the organization needs the following enablers:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        process improvement organization&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Performance Measurements System/ Measurement repository&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        ability to have statistical control over target processes, processes that are predictable and stable&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Statistical analysis tools&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h4>&#xD;
    Tool support&amp;nbsp;&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Statistical analysis tools and spreadsheets are the typical tools used to create and manage process performance&#xD;
    models.&amp;nbsp;IBM Rational Focal Point&amp;nbsp;provides features for&amp;nbsp;performing statistical analysis of project&#xD;
    financials and risk.&lt;br />&#xD;
    &amp;nbsp;&#xD;
&lt;/p></mainDescription>
</org.eclipse.epf.uma:ContentDescription>
