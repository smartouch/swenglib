<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:ContentDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmlns:epf="http://www.eclipse.org/epf" epf:version="1.5.1" xmlns:rmc="http://www.ibm.com/rmc" rmc:version="7.5.1" xmi:id="-D4HUFOFxOs2S_NPPG8SvDw" name="new_supporting_material,_AvxhEMzcEd-mAtWXlhwBWg" guid="-D4HUFOFxOs2S_NPPG8SvDw" changeDate="2011-08-23T15:48:13.649-0700" version="7.5.1">
  <mainDescription>&lt;h3>&#xD;
    Purpose&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    This metric provides the team with some visibility into how frequently they are embracing a key principle of agile&#xD;
    software development-engaging stakeholders.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Monitoring the number of planned versus actual stakeholder interactions helps the team understand whether they are&#xD;
    obtaining feedback at the ends of iterations as planned.&lt;br />&#xD;
    &lt;br />&#xD;
    Regular feedback helps the team:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        remain focused on stakeholders needs and priorities throughout the release&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        address needed changes as early as possible in the lifecycle when rework is less costly to the project.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        reduce the risk of releasing a product that does not deliver the value expected by its stakeholders.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        foster an environment of trust. Stakeholders who are actively engaged in the project and see actions taken based on&#xD;
        their feedback have more faith that the team will deliver what they need.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        reduce the feedback cycle time improving the chances of overall project success&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    The question answered by this metric is:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Are we consistently following through with obtaining the feedback from stakeholders to guide development of our&#xD;
        project or product?&lt;br />&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h3>&#xD;
    Definition&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Count:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Number of planned stakeholder sessions&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Number of actual stakeholder sessions&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h3>&#xD;
    Analysis&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Monitor Planned vs. Actual Stakeholder Feedback Sessions with a line chart. Plot iterations on the X axis and number of&#xD;
    feedback sessions on the Y axis.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;strong>Expected trend&lt;/strong> - Ideally, the number of actual sessions held will equal the number of planned for each&#xD;
    iteration of the release (agile teams plan at least one session at the end of each iteration of the release). In the&#xD;
    simple agile development example where the team conducts one iteration demo at the end of each iteration, both trend&#xD;
    lines will remain relatively flat throughout the release (no major ups and downs) indicating a consistent number of&#xD;
    feedback sessions iteration to iteration throughout the project lifecycle. In large-scale product development, the&#xD;
    number of feedback sessions may vary from iteration to iteration depending on the number of different groups of&#xD;
    stakeholders to which the team will demonstrate working software. Ideally, where there are multiple teams coordinating,&#xD;
    they are continuously integrating and able to deliver real value each iteration. For large-scale teams that are&#xD;
    transitioning, however, whether the team demonstrates to external stakeholders may depend on whether the iteration is&#xD;
    on a boundary where teams integrate their work into something of value to external stakeholders and whether there is&#xD;
    enough value to be demonstrated to external stakeholders.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;strong>Planned sessions trend line remains at zero or slopes downward&lt;/strong> - This trend indicates that the team&#xD;
    may be working in isolation without soliciting stakeholder feedback. They may be working in a waterfall approach,&#xD;
    eliciting requirements early in the lifecycle and not reaching out to stakeholders again until the solution is built&#xD;
    according to the original specification. They are at risk of delivering a product that reflects what the stakeholders&#xD;
    thought they wanted at that time rather than what is needed now. Waiting too long to obtain stakeholder feedback puts&#xD;
    the project at risk of building the wrong thing, and the need to make expensive changes late in the lifecycle.&lt;br />&#xD;
    &lt;br />&#xD;
    &lt;strong>Planned sessions trend line is up and down&lt;/strong> - When the number of planned stakeholder interactions is&#xD;
    not consistent, with several iterations having no planned sessions at all, the team may not be planning to deliver&#xD;
    working, consumable software in each iteration that can be reviewed. While some iterations may be focused on addressing&#xD;
    architectural issues or other items that do not translate directly into observable customer functionality, most&#xD;
    iterations produce something of direct interest to stakeholders that should be reviewed. If the team does not plan for&#xD;
    regular feedback sessions, momentum may be lost in maintaining stakeholder interest and keeping them actively engaged.&#xD;
    When the planned sessions trend line is up and down, but does not reach zero, the team may be planning extra sessions&#xD;
    in specific iterations for additional feedback, stakeholder negotiation, or clarifying questions. In these cases this&#xD;
    trend is no cause for concern.&lt;br />&#xD;
    &lt;br />&#xD;
    &lt;strong>No planned sessions early in the lifecycle&lt;/strong> - This indicates the team may be waiting too long to get&#xD;
    feedback from their stakeholders. They may be building working software but are waiting to have more completed in order&#xD;
    to impress their stakeholders. This could result in unnecessary rework if what was built does not meet stakeholder&#xD;
    expectations.&lt;br />&#xD;
    &lt;br />&#xD;
    &lt;strong>Actual sessions held is lower than planned&lt;/strong> - When this occurs in a single iteration, there may be mild&#xD;
    or no cause for concern. In some cases, however, the team may have over-committed for the iteration or have quality&#xD;
    issues, resulting in the inability to demonstrate results. The team should adjust their plans for the next iteration&#xD;
    accordingly and resume consistent feedback sessions. In other cases, the team may be having difficulty identifying&#xD;
    stakeholders to invite to the iteration demos or may be having difficulty working with the product owner to coordinate&#xD;
    based on stakeholder availability.&lt;br />&#xD;
    When this occurs as a trend for a number of iterations, the team should determine why they are unable or unwilling to&#xD;
    solicit stakeholder feedback. Continuing this trend places the project at risk.&lt;br />&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    If the agile development team or managers are interested in viewing the planned vs actual stakeholder feedback sessions&#xD;
    over time, perhaps to look for opportunities to further improve in the next release, they can monitor planned and&#xD;
    actual trend lines throughout the release.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Frequency and reporting&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Each iteration, update the number of sessions planned for future iterations and the number of actual sessions held at&#xD;
    the end of the previous iteration. Although the team may have an initial plan for the number of feedback sessions for&#xD;
    particular iterations, they will likely need to update the plan based on the teamâ€™s progress. User stories are&#xD;
    reprioritized, added, deleted and updated in the release backlog as needed throughout the release.&lt;br />&#xD;
    &lt;br />&#xD;
    During the iteration retrospective, the team can discuss whether they met the goal for the number of feedback sessions&#xD;
    during the previous iteration or if they need to work with their product owner or management team to take action to&#xD;
    improve in the upcoming iteration.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The number of planned sessions is captured at the beginning of each iteration during iteration planning. Agile teams&#xD;
    typically plan to have at least one stakeholder feedback session in each iteration to demonstrate and collect feedback&#xD;
    on the results produced in that iteration. Additional sessions may be planned as needed.&lt;br />&#xD;
    &lt;br />&#xD;
    The number of actual sessions held is counted at the end of the iteration during iteration review and assessment. The&#xD;
    team updates the trend chart and analyzes results. The team discusses concerns as part of the iteration reflection. The&#xD;
    team may have to raise issues with the ScrumMaster, Product Owner or management for help in getting them resolved.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    &lt;br />&#xD;
    Collection&amp;nbsp;and reporting tools&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Source data&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Number of stakeholder feedback session work items created and assigned in each iteration.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Number of stakeholder feedback session work items completed in each iteration.&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    The team can track stakeholder feedback sessions in IBM Rational Team Concert (RTC) by creating a custom work item&#xD;
    type. Create a work item for each planned session and mark it as &quot;resolved&quot; upon completion. Define a custom report in&#xD;
    RTC to track planned versus completed stakeholder feedback sessions in each iteration.&lt;br />&#xD;
    &lt;br />&#xD;
    Data can also be collected and reported in a simple spreadsheet.&lt;br />&#xD;
    &lt;br />&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Assumptions and prerequisites&#xD;
&lt;/h3>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Iterations are time-boxed and deliver working software that can be reviewed by stakeholders to solicit their&#xD;
        feedback. Frequent delivery through short iterations gives a stakeholder the opportunity to see progress on a&#xD;
        consistent basis. In cases where iterations produce results without easily observable customer features, the team&#xD;
        can identify other methods to demonstrate progress and results (e.g. overview discussion, architectural models)&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Appropriate stakeholders have been identified and are committed to participating in iteration demos. They&#xD;
        understand the importance of providing feedback and are willing to be actively engaged in the project.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        There is a shared understanding of the project vision and requirements as they are elaborated. Schedule, resource,&#xD;
        and budget constraints are well-understood.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        When several sessions are held to review the same content in the same way in order to accommodate different&#xD;
        stakeholder schedules, they count as one session. If the team is targeting different types of stakeholders (i.e.,&#xD;
        end users and CxO level executives for example), each counts as a different different. Remember that a different&#xD;
        metric is used to track actual participation of stakeholders in each session.&lt;br />&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h3>&#xD;
    Pitfalls and advice&#xD;
&lt;/h3>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Teams that are coordinating in a large-scale product development environment will need to coordinate planning for&#xD;
        stakeholder engagement. Stakeholders who receive multiple requests from multiple teams may be less likely to show&#xD;
        up to demos and more confused by what appears to be an overall lack of coordination by the teams.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        This metric can be tracked at the organization level by rolling up results from multiple projects. This helps the&#xD;
        organization understand how well teams are adopting the practice of obtaining continuous feedback, and determine if&#xD;
        the practice is resulting in improvements to customer value and other key indicators of project success.&lt;br />&#xD;
    &lt;/li>&#xD;
&lt;/ul></mainDescription>
</org.eclipse.epf.uma:ContentDescription>
