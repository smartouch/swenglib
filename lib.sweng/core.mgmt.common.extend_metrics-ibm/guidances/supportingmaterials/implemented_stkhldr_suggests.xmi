<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:ContentDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmlns:rmc="http://www.ibm.com/rmc" rmc:version="7.5.1" xmlns:epf="http://www.eclipse.org/epf" epf:version="1.5.1" xmi:id="-zAjcCSgVngOIXHL5YZNfdQ" name="new_supporting_material,_OTckoMzgEd-mAtWXlhwBWg" guid="-zAjcCSgVngOIXHL5YZNfdQ" changeDate="2011-06-29T14:39:55.296-0700" version="7.5.1">
  <mainDescription>&lt;h3>&#xD;
    Purpose&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    The metric is created and used by the development team conducting the feedback sessions to assess the value of the&#xD;
    sessions. The overall evaluation should take into account the combined metrics for the different data points for&#xD;
    Stakeholder Feedback, but the value categories for this particular metric can indicate very clearly where product&#xD;
    improvements have been made. These can be used by development leaders and executives to articulate the effectiveness of&#xD;
    using stakeholder feedback in the development process.&lt;br />&#xD;
    &lt;br />&#xD;
    The number of implemented suggestions across the high value categories can be used to articulate the overall&#xD;
    effectiveness of the feedback sessions.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Definition&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Count: Total number of suggestions implemented&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Analysis&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    From the list of the suggestions gathered at the feedback session, separate the implemented suggestions into feedback&#xD;
    categories. Note that a single suggestion might fall into multiple categories.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The number of suggestions received and implemented will help in assessing the value of the stakeholder feedback&#xD;
    sessions. However the number alone is not representative of any particular value. The highest value suggestions are&#xD;
    those that cause action to be taken, followed by those that confirm a design direction. The metrics gathered here will&#xD;
    separate the implemented suggestions into value categories. It will then be easy to see the distribution of suggestions&#xD;
    across these high value categories.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Implemented Suggestion&lt;br />&#xD;
    &lt;br />&#xD;
&lt;/p>&#xD;
&lt;table title=&quot;&quot; border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;2&quot; width=&quot;85%&quot;>&#xD;
    &lt;tbody>&#xD;
        &lt;tr bgcolor=&quot;#CCCCCC&quot;>&#xD;
            &lt;td>&#xD;
                &lt;strong>Value Category&lt;/strong>&#xD;
            &lt;/td>&#xD;
            &lt;td>&#xD;
                &lt;strong>Number Implemented&lt;/strong>&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
        &lt;tr>&#xD;
            &lt;td>&#xD;
                Enhances the design with function &lt;strong>not previously included&lt;/strong>&#xD;
            &lt;/td>&#xD;
            &lt;td>&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
        &lt;tr>&#xD;
            &lt;td>&#xD;
                Redirects the design down &lt;strong>an alternate path from the one being considered&lt;/strong>&#xD;
            &lt;/td>&#xD;
            &lt;td>&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
        &lt;tr>&#xD;
            &lt;td>&#xD;
                &lt;strong>Avoids a problem identified&lt;/strong> by the stakeholder during a session&#xD;
            &lt;/td>&#xD;
            &lt;td>&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
        &lt;tr>&#xD;
            &lt;td>&#xD;
                &lt;strong>Reduces the amount of rework&lt;/strong> required to implement a significant change now instead of&#xD;
                later&#xD;
            &lt;/td>&#xD;
            &lt;td>&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
        &lt;tr>&#xD;
            &lt;td>&#xD;
                &lt;strong>Improve the usability&lt;/strong> of the product&#xD;
            &lt;/td>&#xD;
            &lt;td>&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
        &lt;tr>&#xD;
            &lt;td>&#xD;
                &lt;strong>Clarify or confirm requirements&lt;/strong> being implemented&#xD;
            &lt;/td>&#xD;
            &lt;td>&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
        &lt;tr>&#xD;
            &lt;td>&#xD;
                Stakeholder finds &lt;strong>business value&lt;/strong> in the design&#xD;
            &lt;/td>&#xD;
            &lt;td>&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/tbody>&#xD;
&lt;/table>&lt;br />&#xD;
There is some interpretation of the data across these value categories that can help you decide if your&#xD;
stakeholder&amp;nbsp;feedback&amp;nbsp;activities&amp;nbsp;are appropriate to your place in the development cycle.&lt;br />&#xD;
&lt;br />&#xD;
Looking across multiple iterations over time, one would expect to see an evolution of the types of suggestions being&#xD;
suggested and accepted into the design. In the early iterations when the design is still in concept, one should expect&#xD;
suggestions that modify the design, enhancing and redirecting it to meet the stakeholder's needs. This phase will also&#xD;
surface problems with the design. In addition, this phase can also provide valuable clarification and confirmation of&#xD;
design requirements.&lt;br />&#xD;
&lt;br />&#xD;
In the mid-phase iterations, the design should be more solid, and suggestions that redirect the design should be less&#xD;
prevalent. At this time one should expect suggestions that identify problems in the implementation, improvements for&#xD;
usability, and clarification and confirmation of the design requirements having been met.&lt;br />&#xD;
&lt;br />&#xD;
In the late iterations, the design and implementation is nearly complete. During this phase one should expect small&#xD;
suggestions for improving the usability of the implementation and confirmation that the requirements have been met. This is&#xD;
not a good time to find issues with the design. If this happens, there can be multiple causes to consider, but changes at&#xD;
this time will be costlier, or they will be deferred, lessening the value of the project to the stakeholder.&lt;br />&#xD;
&lt;br />&#xD;
&lt;br />&#xD;
The following figure shows a hypothetical distribution of suggestions across 3 iterations. These are reasonable&#xD;
distributions for the respective iteration timeframes. &lt;br />&#xD;
&lt;br />&#xD;
&lt;p>&#xD;
    &lt;img alt=&quot;Stakeholder Feedback Across Iterations&quot; src=&quot;resources/feedback_across_iterations.gif&quot; width=&quot;600&quot;&#xD;
    height=&quot;346&quot; />&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Frequency and reporting&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Implemented Stakeholder Feedback suggestions&amp;nbsp;should be measured at the end of an iteration. It will be at this&#xD;
    time that the data will indicate which suggestions are being integrated into the current design.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    &lt;br />&#xD;
    Collection and&amp;nbsp;reporting tools&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Stakeholder&amp;nbsp;suggestion data can be collected in IBM&amp;reg; Rational&amp;reg; Team Concert&amp;reg;. The plan overview page is used to&#xD;
    collect unstructured information that applies to the iteration plan. This can include all of the Stakeholder Feedback&#xD;
    information gathered. The plan overview section also provides a description of the high-level tasks planned for a plan.&#xD;
    You can include the following sections in the overview of the plan: Stakeholder Objectives, Notes from the Stakeholder&#xD;
    Meetings, list of deliverables for the iteration and the related Stakeholder feedback, Key Stakeholder Meeting schedule&#xD;
    dates, and stakeholders and other contacts.&lt;br />&#xD;
    &lt;br />&#xD;
    Once the iteration is complete, the stakeholder feedback items to be implemented can be translated into work items for&#xD;
    the team and prioritized for implementation. Once they are well on their way to being implemented, they should appear&#xD;
    in the metric.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    &lt;br />&#xD;
    Assumptions and pre-requisites&#xD;
&lt;/h3>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Intended customer interaction activities should be planned during release planning and the plan used to assess&#xD;
        customer interaction effectiveness.&lt;br />&#xD;
        &lt;br />&#xD;
        &lt;br />&#xD;
    &lt;/li>&#xD;
&lt;/ul></mainDescription>
</org.eclipse.epf.uma:ContentDescription>
