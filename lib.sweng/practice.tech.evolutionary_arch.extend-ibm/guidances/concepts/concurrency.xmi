<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:ContentDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmlns:epf="http://www.eclipse.org/epf" epf:version="1.5.1" xmlns:rmc="http://www.ibm.com/rmc" rmc:version="7.5.1" xmi:id="-0668FDrLSYWKGC47Pxyklw" name="new_concept,_O4WLoH3FEd2eJPu0NyCdUg" guid="-0668FDrLSYWKGC47Pxyklw" changeDate="2008-09-08T09:48:51.656-0700" version="7.5.0">
  <mainDescription>&lt;p>&#xD;
    Concurrency is the tendency for things to happen at the same time in a system. Concurrency is a natural phenomenon, of&#xD;
    course. In the real world, at any given time, many things are happening simultaneously. When we design software to&#xD;
    monitor and control real-world systems, we must deal with this natural concurrency.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    When dealing with concurrency issues in software systems, there are generally two aspects that are important: being&#xD;
    able to detect and respond to external events occurring in a random order, and ensuring that these events are responded&#xD;
    to in some minimum required interval.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    If each concurrent activity evolved independently, in a truly parallel fashion, this would be relatively simple: we&#xD;
    could simply create separate programs to deal with each activity. The challenges of designing concurrent systems arise&#xD;
    mostly because of the interactions which happen between concurrent activities. When concurrent activities interact,&#xD;
    some sort of coordination is required.&#xD;
&lt;/p>&#xD;
&lt;p align=&quot;center&quot;>&#xD;
    &lt;img height=&quot;357&quot; alt=&quot;Diagram is detailed in the content.&quot; src=&quot;./resources/co_cncr1.gif&quot; width=&quot;297&quot; />&#xD;
&lt;/p>&#xD;
&lt;p class=&quot;picturetext&quot; align=&quot;center&quot;>&#xD;
    Figure 1:&amp;nbsp; Example of concurrency at work: parallel activities that do not interact have simple concurrency&#xD;
    issues. It is when parallel activities interact or share the same resources that concurrency issues become important.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Vehicular traffic provides a useful analogy. Parallel traffic streams on different roadways having little interaction&#xD;
    cause few problems. Parallel streams in adjacent lanes require some coordination for safe interaction, but a much more&#xD;
    severe type of interaction occurs at an intersection, where careful coordination is required.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    &lt;a id=&quot;Why are we interested?&quot; name=&quot;Why are we interested?&quot;>Why are we interested in Concurrency?&lt;/a>&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Some of the driving forces for concurrency are external. That is, they are imposed by the demands of the environment.&#xD;
    In real-world systems many things are happening simultaneously and must be addressed &quot;in real-time&quot; by software. To do&#xD;
    so, many real-time software systems must be &quot;reactive.&quot; They must respond to externally generated events which may&#xD;
    occur at somewhat random times, in some-what random order, or both.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Designing a conventional procedural program to deal with these situations is extremely complex. It can be much simpler&#xD;
    to partition the system into concurrent software elements to deal with each of these events. The key phrase here is&#xD;
    &quot;can be&quot;, since complexity is also affected by the degree of interaction between the events.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    There can also be internally inspired reasons for concurrency [&lt;a class=&quot;elementLinkWithUserText&quot; href=&quot;./../../../core.tech.common.extend-ibm/guidances/supportingmaterials/tech_references_17D34A60.html#LEA97&quot; guid=&quot;_OKj94D8iEd2AxfTL63EayA&quot;>LEA97&lt;/a>]. Performing tasks in parallel can substantially speed up the computational&#xD;
    work of a system if multiple CPUs are available. Even within a single processor, multitasking can dramatically speed&#xD;
    things up by preventing one activity from blocking another while waiting for I/O, for example. A common situation where&#xD;
    this occurs is during the startup of a system. There are often many components, each of which requires time to be made&#xD;
    ready for operation. Performing these operations sequentially can be painfully slow.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Controllability of the system can also be enhanced by concurrency. For example, one function can be started, stopped,&#xD;
    or otherwise influenced in mid-stream by other concurrent functions-something extremely difficult to accomplish without&#xD;
    concurrent components.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    &lt;a id=&quot;Why is it hard?&quot; name=&quot;Why is it hard?&quot;>What makes Concurrent Software Difficult?&lt;/a>&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    With all these benefits, why don't we use concurrent programming everywhere?&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Most computers and programming languages are inherently sequential. A procedure or processor executes one instruction&#xD;
    at a time. Within a single sequential processor, the illusion of concurrency must be created by interleaving the&#xD;
    execution of different tasks. The difficulties lie not so much in the mechanics of doing so, but in the determination&#xD;
    of just when and how to interleave program segments which may interact with each other.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Although achieving concurrency is easy with multiple processors, the interactions become more complex. First there is&#xD;
    the question of communication between tasks running on different processors. Usually there are several layers of&#xD;
    software involved, which increase complexity and add timing overhead. Determinism is reduced in multi-CPU systems,&#xD;
    since clocks and timing may differ, and components may fail independently.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Finally, concurrent systems can be more difficult to understand because they lack an explicit global system state. The&#xD;
    state of a concurrent system is the aggregate of the states of its components.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    &lt;a id=&quot;Elevator example&quot; name=&quot;Elevator example&quot;>Example of a Concurrent, Real-time System: An Elevator System&lt;/a>&#xD;
&lt;/h3>&#xD;
&lt;p align=&quot;left&quot;>&#xD;
    As an example to illustrate the concepts to be discussed, we will use an elevator system. More precisely, we mean a&#xD;
    computer system designed to control a group of elevators at one location in a building. Obviously there may be many&#xD;
    things going on concurrently within a group of elevators-or nothing at all! At any point in time someone on any floor&#xD;
    may request an elevator, and other requests may be pending. Some of the elevators may be idle, while others are either&#xD;
    carrying passengers, or going to answer a call, or both. Doors must open and close at appropriate times. Passengers may&#xD;
    be obstructing the doors, or pressing door open or close buttons, or selecting floors-then changing their minds.&#xD;
    Displays need to be updated, motors need to be controlled, and so on, all under the supervision of the elevator control&#xD;
    system. Overall, it's a good model for exploring concurrency concepts, and one for which we share a reasonably common&#xD;
    degree of understanding and a working vocabulary.&#xD;
&lt;/p>&#xD;
&lt;p class=&quot;picturetext&quot; align=&quot;center&quot;>&#xD;
    &lt;br />&#xD;
    &lt;img height=&quot;242&quot; alt=&quot;Diagram is detailed in the content.&quot; src=&quot;./resources/co_cncr2.gif&quot; width=&quot;399&quot; />&lt;br />&#xD;
    Figure 2:&amp;nbsp;&amp;nbsp; A scenario involving two elevators and five potential passengers distributed over 11 floors.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    As potential passengers place demands upon the system at different times, the system attempts to provide the best&#xD;
    overall service by selecting elevators to answer calls based upon their current states and projected response times.&#xD;
    For example, when the first potential passenger, Andy, calls for an elevator to go down, both are idle, so the closest&#xD;
    one, Elevator 2, responds, although it must first travel upward to get to Andy. On the other hand, a few moments later&#xD;
    when the second potential passenger, Bob, requests an elevator to go up, the more distant Elevator 1 responds, since it&#xD;
    is known that Elevator 2 must travel downward to an as-yet-unknown destination before it can answer an up call from&#xD;
    below.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    &lt;a id=&quot;Concurrency as a simplifying strategy&quot; name=&quot;Concurrency as a simplifying strategy&quot;>Concurrency as a Simplifying&#xD;
    Strategy&lt;/a>&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    If the elevator system only had one elevator and that elevator had only to serve one passenger at a time, we might be&#xD;
    tempted to think we could handle it with an ordinary sequential program. Even for this &quot;simple&quot; case, the program would&#xD;
    require many branches to accommodate different conditions. For example, if the passenger never boarded and selected a&#xD;
    floor, we would want to reset the elevator to allow it to respond to another call.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The normal requirement to handle calls from multiple potential passengers and requests from multiple passengers&#xD;
    exemplifies the external driving forces for concurrency we discussed earlier. Because the potential passengers lead&#xD;
    their own concurrent lives, they place demands on the elevator at seemingly random times, no matter what the state of&#xD;
    the elevator. It is extremely difficult to design a sequential program that can respond to any of these external events&#xD;
    at any time while continuing to guide the elevator according to past decisions.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    &lt;a id=&quot;Abstracting Concurrency&quot; name=&quot;Abstracting Concurrency&quot;>Abstracting Concurrency&lt;/a>&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    In order to design concurrent systems effectively, we must be able to reason about the role of concurrency in the&#xD;
    system, and in order to do this we need abstractions of concurrency itself.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The fundamental building blocks of concurrent systems are &quot;activities&quot; which proceed more or less independently of each&#xD;
    other. A useful graphical abstraction for thinking about such activities is Buhr's &quot;timethreads.&quot; [&lt;a class=&quot;elementLinkWithUserText&quot; href=&quot;./../../../core.tech.common.extend-ibm/guidances/supportingmaterials/tech_references_17D34A60.html#BUH96&quot; guid=&quot;_OKj94D8iEd2AxfTL63EayA&quot;>BUH96&lt;/a>] Our elevator scenario in Figure 3 actually used a form of them. Each activity&#xD;
    is represented as a line along which the activity travels. The large dots represent places where an activity starts or&#xD;
    waits for an event to occur before proceeding. One activity can trigger another to continue, which is represented in&#xD;
    the timethread notation by touching the waiting place on the other timethread.&#xD;
&lt;/p>&#xD;
&lt;p align=&quot;center&quot;>&#xD;
    &lt;img height=&quot;190&quot; alt=&quot;Diagram is detailed in the content.&quot; src=&quot;./resources/co_cncr3.gif&quot; width=&quot;273&quot; />&#xD;
&lt;/p>&#xD;
&lt;p class=&quot;picturetext&quot; align=&quot;center&quot;>&#xD;
    Figure 3:&amp;nbsp;&amp;nbsp; A visualization of threads of execution&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The basic building blocks of software are procedures and data structures, but these alone are inadequate for reasoning&#xD;
    about concurrency. As processor executes a procedure it follows a particular path depending upon current conditions.&#xD;
    This path may be called the &quot;thread of execution&quot; or &quot;thread of control.&quot; This thread of control may take different&#xD;
    branches or loops depending upon the conditions which exist at the time, and in real-time systems may pause for a&#xD;
    specified period or wait for a scheduled time to resume.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    From the point of view of the program designer, the thread of execution is controlled by the logic in the program and&#xD;
    scheduled by the operating system. When the software designer chooses to have one procedure invoke others, the thread&#xD;
    of execution jumps from one procedure to another, then jumping back to continue where it left off when a return&#xD;
    statement is encountered.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    From the point of view of the CPU, there is only one main thread of execution that weaves through the software,&#xD;
    supplemented by short separate threads which are executed in response to hardware interrupts. Since everything else&#xD;
    builds on this model, it is important for designers to know about it. Designers of real-time systems, to a greater&#xD;
    degree than designers of other types of software, must understand how a system works at a very detailed level. This&#xD;
    model, however, is at such a low level of abstraction that it can only represent concurrency very coarse&#xD;
    granularity-that of the CPU. To design complex systems, it is useful to be able to work at various levels of&#xD;
    abstraction. Abstraction, of course, is the creation of a view or model that suppresses unnecessary details so that we&#xD;
    may focus on what is important to the problem at hand.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    To move up one level, we commonly think of software in terms of layers. At the most fundamental level, the Operating&#xD;
    System (OS) is layered between the hard-ware and the application software. It provides the application with&#xD;
    hardware-based services, such as memory, timing, and I/O, but it abstracts the CPU to create a virtual machine that is&#xD;
    independent of the actual hardware configuration.&#xD;
&lt;/p>&lt;br /></mainDescription>
</org.eclipse.epf.uma:ContentDescription>
