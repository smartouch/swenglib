<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:ContentDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmlns:epf="http://www.eclipse.org/epf" epf:version="1.5.1" xmlns:rmc="http://www.ibm.com/rmc" rmc:version="7.5.1" xmi:id="-K-Z8T7QiT0naTUos9AJhjA" name="test_strategy,_87RzwHHTEdyzS55ez-koKA" guid="-K-Z8T7QiT0naTUos9AJhjA" changeDate="2007-12-27T11:47:59.562-0800" version="7.2">
  <mainDescription>&lt;p>&#xD;
    A strategy for the testing portion of a project describes the general approach and objectives of the test tasks. It&#xD;
    includes those stages of testing (unit, integration, and system) to be addressed and the kinds of testing (function,&#xD;
    performance, load, stress) to be performed.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The strategy defines:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Testing techniques and tools to be used.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        What test completion and success criteria will be used. For example, the criteria might allow the software to&#xD;
        progress to acceptance testing when 95% of the test cases have been successfully executed. Another criterion is&#xD;
        code coverage. This criterion may, in a safety-critical system, be that 100% of the code should be covered by&#xD;
        tests.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Special considerations affect resource requirements or have schedule implications such as:&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;div style=&quot;MARGIN-LEFT: 2em&quot;>&#xD;
    &lt;ul>&#xD;
        &lt;li>&#xD;
            testing all interfaces to external systems&#xD;
        &lt;/li>&#xD;
        &lt;li>&#xD;
            simulating physical damage or security threat&#xD;
        &lt;/li>&#xD;
    &lt;/ul>&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Some organizations have defined corporate test strategies, in which case you work to apply those strategies to your&#xD;
    specific project.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The most important dimensions around which you should plan your test tasks are:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        What iteration you are you in and what are the goals of that iteration?&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        What stage of test (unit test, integration test, system test) are you are performing? You might work all stages of&#xD;
        test in one iteration.&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    Now take a look at how the characteristics of your test tasks can change depending on where you are in the previously&#xD;
    mentioned test dimensions. There are many characteristics you could look at, such as resources needed and time spent,&#xD;
    but, at this point, focus on what is important to defining your test strategy such as:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        types of test (functional, stress, volume, performance, usability, distribution, and so on)&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        evaluation criteria used (code-based test coverage, requirements-based test coverage, number of defects,&#xD;
        mean-time-between-failure, and so on)&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        testing techniques used (manual and automated)&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    There is no general pattern for how the types of tests are distributed over the test cycles. You focus on different&#xD;
    types of tests depending on the number of iterations, the size of the iteration, and what kind of project this is that&#xD;
    you're testing.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    You will find that the system test stage has a strong focus on making sure you are covering all testable requirements&#xD;
    expressed in terms of a set of test cases. This means your completion criteria will focus on requirements-based test&#xD;
    coverage. In the integration and unit test stages, you will find code-based test coverage is a more appropriate&#xD;
    completion criterion. The next figure shows how the use of these two types of test coverage measures can change as you&#xD;
    develop new iterations of your software.&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        The test plan should define sets of completion criteria for unit test, integration test, and system test.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        You may have different sets of completion criteria defined for individual iterations.&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p align=&quot;center&quot;>&#xD;
    &lt;img height=&quot;183&quot; alt=&quot;Requirements and Code Based Areas of a Test Table Image&quot; src=&quot;./resources/testr001.gif&quot;     width=&quot;307&quot; />&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    On your project, consider automating your tests as much as possible, specifically the kind of tests you repeat several&#xD;
    times (regression tests). Keep in mind that it costs time and resources to create and maintain automated tests. There&#xD;
    will always be some amount of manual testing on each project. The following figure illustrates when and in what stages&#xD;
    of testing you'll probably perform manual tests.&#xD;
&lt;/p>&#xD;
&lt;p align=&quot;center&quot;>&#xD;
    &lt;img height=&quot;183&quot; alt=&quot;Test Table with Manual Test Areas Circled Image&quot; src=&quot;./resources/testr002.gif&quot; width=&quot;307&quot; />&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;b>Example&lt;/b>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The following tables show when the different types of tests are identified and provide an example of the completion&#xD;
    criteria to define. The first table shows a &quot;typical&quot; MIS project.&#xD;
&lt;/p>&#xD;
&lt;div align=&quot;center&quot;>&#xD;
    &lt;table     style=&quot;BORDER-RIGHT: rgb(128,128,128) 1px solid; BORDER-TOP: rgb(128,128,128) 1px solid; BORDER-LEFT: rgb(128,128,128) 1px solid; BORDER-BOTTOM: rgb(128,128,128) 1px solid&quot;      cellspacing=&quot;0&quot; bordercolordark=&quot;#808080&quot; cellpadding=&quot;4&quot; width=&quot;85%&quot; bordercolorlight=&quot;#808080&quot; border=&quot;1&quot;>&#xD;
        &lt;tbody>&#xD;
            &lt;tr>&#xD;
                &lt;th width=&quot;9%&quot;>&#xD;
                    &lt;b>Iteration test&lt;/b>&#xD;
                &lt;/th>&#xD;
                &lt;th width=&quot;45%&quot;>&#xD;
                    &lt;b>System test&lt;/b>&#xD;
                &lt;/th>&#xD;
                &lt;th width=&quot;28%&quot;>&#xD;
                    &lt;b>Integration test&lt;/b>&#xD;
                &lt;/th>&#xD;
                &lt;th width=&quot;18%&quot;>&#xD;
                    &lt;b>Unit test&lt;/b>&#xD;
                &lt;/th>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;9%&quot;>&#xD;
                    Iteration 1&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;45%&quot;>&#xD;
                    Automated performance testing for all use cases.&lt;br />&#xD;
                     · All planned tests have been executed.&lt;br />&#xD;
                     · All severity 1 defects have been addressed.&lt;br />&#xD;
                     · All planned tests have been re-executed and no new severity 1 defects have been identified.&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;28%&quot;>&#xD;
                    None&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;18%&quot;>&#xD;
                    Informal testing&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;9%&quot;>&#xD;
                    Iteration 2&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;45%&quot;>&#xD;
                    Automated performance and functionality testing for all new use cases and the previous as regression&#xD;
                    test.&lt;br />&#xD;
                     · All planned tests have been executed.&lt;br />&#xD;
                     · All severity 1 and 2 defects have been addressed.&lt;br />&#xD;
                     · All planned tests have been re-executed and no new severity 1 or 2 defects have been identified.&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;28%&quot;>&#xD;
                    None&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;18%&quot;>&#xD;
                    Informal testing&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;9%&quot;>&#xD;
                    Iteration 3&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;45%&quot;>&#xD;
                    Automated functionality and negative testing for all new use cases, and all the previous as regression&#xD;
                    test; 95% of test cases have to pass.&lt;br />&#xD;
                     · All planned tests have been executed.&lt;br />&#xD;
                     · All severity 1, 2, and 3 defects identified.&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;28%&quot;>&#xD;
                    Automated testing, 70% code coverage.&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;18%&quot;>&#xD;
                    Informal testing&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;9%&quot;>&#xD;
                    Iteration 4&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;45%&quot;>&#xD;
                    Automated functionality and negative testing for all use cases, manual testing for all parts that are&#xD;
                    not automated, and all the previous as regression test. 100% of test cases have to pass.&lt;br />&#xD;
                     · All planned tests have been executed.&lt;br />&#xD;
                     · All severity 1, 2, and 3 defects have been addressed.&lt;br />&#xD;
                     · All planned tests have been re-executed and no new severity 1 or 2 defects have been identified.&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;28%&quot;>&#xD;
                    Automated testing, 80% code coverage.&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;18%&quot;>&#xD;
                    Informal testing&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
        &lt;/tbody>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    The second table shows the types of test and completion criteria applied for a &lt;i>typical&lt;/i> safety-critical system.&#xD;
&lt;/p>&#xD;
&lt;div align=&quot;center&quot;>&#xD;
    &lt;table     style=&quot;BORDER-RIGHT: rgb(128,128,128) 1px solid; BORDER-TOP: rgb(128,128,128) 1px solid; BORDER-LEFT: rgb(128,128,128) 1px solid; BORDER-BOTTOM: rgb(128,128,128) 1px solid&quot;      cellspacing=&quot;0&quot; bordercolordark=&quot;#808080&quot; cellpadding=&quot;4&quot; width=&quot;85%&quot; bordercolorlight=&quot;#808080&quot; border=&quot;1&quot;>&#xD;
        &lt;tbody>&#xD;
            &lt;tr>&#xD;
                &lt;th width=&quot;9%&quot;>&#xD;
                    &lt;b>Iteration test&lt;/b>&#xD;
                &lt;/th>&#xD;
                &lt;th width=&quot;45%&quot;>&#xD;
                    &lt;b>System test&lt;/b>&#xD;
                &lt;/th>&#xD;
                &lt;th width=&quot;28%&quot;>&#xD;
                    &lt;b>Integration test&lt;/b>&#xD;
                &lt;/th>&#xD;
                &lt;th width=&quot;18%&quot;>&#xD;
                    &lt;b>Unit test&lt;/b>&#xD;
                &lt;/th>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td>&#xD;
                    Iteration 1&#xD;
                &lt;/td>&#xD;
                &lt;td>&#xD;
                    Automated performance testing for all use cases; 100% test-case coverage.&lt;br />&#xD;
                     · All planned tests have been executed.&lt;br />&#xD;
                     · All severity 1 defects have been addressed.&lt;br />&#xD;
                     · All planned tests have been re-executed and no new defects have been identified.&#xD;
                &lt;/td>&#xD;
                &lt;td>&#xD;
                    None&#xD;
                &lt;/td>&#xD;
                &lt;td>&#xD;
                    None&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td>&#xD;
                    Iteration 2&#xD;
                &lt;/td>&#xD;
                &lt;td>&#xD;
                    Automated performance, functionality, and negative testing for all use cases; 100% test-case&#xD;
                    coverage.&lt;br />&#xD;
                     · All planned tests have been executed.&lt;br />&#xD;
                     · All severity 1 or 2 defects have been addressed.&lt;br />&#xD;
                     · All planned tests have been re-executed and no new defects have been identified.&#xD;
                &lt;/td>&#xD;
                &lt;td>&#xD;
                    Automated performance testing&#xD;
                &lt;/td>&#xD;
                &lt;td>&#xD;
                    Informal testing&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td>&#xD;
                    Iteration 3&#xD;
                &lt;/td>&#xD;
                &lt;td>&#xD;
                    Automated performance, functionality, negative usability, and documentation testing for all use cases;&#xD;
                    100% test-case coverage.&lt;br />&#xD;
                     · All planned tests have been executed.&lt;br />&#xD;
                     · All severity 1, 2, and 3 defects have been addressed.&lt;br />&#xD;
                     · All planned tests have been re-executed and no new defects have been identified.&#xD;
                &lt;/td>&#xD;
                &lt;td>&#xD;
                    Automated performance testing and the previous as regression test&#xD;
                &lt;/td>&#xD;
                &lt;td>&#xD;
                    Automated testing, 70% code coverage&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td>&#xD;
                    Iteration 4&#xD;
                &lt;/td>&#xD;
                &lt;td>&#xD;
                    Automated performance, functionality, negative usability, and documentation testing for all use cases;&#xD;
                    100% test-case coverage.&lt;br />&#xD;
                     · All planned tests have been executed.&lt;br />&#xD;
                     · All severity 1, 2, and 3 defects have been addressed.&lt;br />&#xD;
                     · All planned tests have been re-executed and no defects have been identified.&#xD;
                &lt;/td>&#xD;
                &lt;td>&#xD;
                    Automated performance testing and the previous as regression testing&#xD;
                &lt;/td>&#xD;
                &lt;td>&#xD;
                    Automated testing, 80% code coverage&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
        &lt;/tbody>&#xD;
    &lt;/table>&#xD;
&lt;/div>&lt;br />&#xD;
&lt;br /></mainDescription>
</org.eclipse.epf.uma:ContentDescription>
