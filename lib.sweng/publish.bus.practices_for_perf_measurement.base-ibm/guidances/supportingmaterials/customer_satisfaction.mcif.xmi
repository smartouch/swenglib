<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:ContentDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmlns:epf="http://www.eclipse.org/epf" epf:version="1.5.1" xmlns:rmc="http://www.ibm.com/rmc" rmc:version="7.5.1" xmi:id="-qsD3CBV-Zjm6Ix3Ts9z_ng" name="new_supporting_material,_aWw2wOEmEd6AqdnazgLzJg" guid="-qsD3CBV-Zjm6Ix3Ts9z_ng" changeDate="2010-01-08T10:25:14.234-0800" version="7.5.0">
  <mainDescription>&lt;h3>&#xD;
    Purpose&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Customer Satisfaction is a key indicator of project success. Monitoring this metric throughout the lifecycle helps the&#xD;
    team understand whether they are delivering the value that stakeholders need and expect.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    As the system grows, stakeholders provide frequent feedback describing their perception of the output. Based on this&#xD;
    feedback, the team can adjust as necessary to ensure they are delivering the correct system that meets the needs of its&#xD;
    stakeholders. Ongoing measurement allows the team to see the impact of their adjustments.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Definition&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Ratings obtained through stakeholder surveys provide a measurement of client satisfaction and perception of value. Each&#xD;
    survey contains qualitative questions answered subjectively by stakeholders. Typically, stakeholders are asked to&#xD;
    provide answers in a combination of textual and numeric responses. Answers provided using a defined scale allow for&#xD;
    quantifiable results, while prose answers can help with detailed root cause analysis of the numerical results.&lt;br />&#xD;
    &lt;br />&#xD;
    The following example survey question is answered with both a numeric rating and textual comments.&#xD;
&lt;/p>&lt;br />&#xD;
&lt;table title=&quot;&quot; cellspacing=&quot;0&quot; cellpadding=&quot;2&quot; width=&quot;85%&quot; border=&quot;1&quot;>&#xD;
    &lt;tbody>&#xD;
        &lt;tr>&#xD;
            &lt;td>&#xD;
                &lt;p>&#xD;
                    On a scale of 1-5 (5 being the most satisfied and 1 being the least), how satisfied are you with the&#xD;
                    system's expected capabilities? Does it meet your needs in terms of functionality?&#xD;
                &lt;/p>&#xD;
            &lt;/td>&#xD;
            &lt;td>&#xD;
                &lt;br />&#xD;
                &lt;br />&#xD;
                &lt;p>&#xD;
                    1 2 3 4 5&#xD;
                &lt;/p>&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
        &lt;tr>&#xD;
            &lt;td>&#xD;
                &lt;p>&#xD;
                    Which expectations were met or exceeded? Which expectations were not met?&#xD;
                &lt;/p>&#xD;
                &lt;p>&#xD;
                    Provide your comments here:&#xD;
                &lt;/p>&lt;br />&#xD;
                &lt;br />&#xD;
            &lt;/td>&#xD;
            &lt;td>&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/tbody>&#xD;
&lt;/table>&lt;br />&#xD;
&lt;p>&#xD;
    A good way to monitor Customer Satisfaction over time is to use a trend line. Collect ratings after each iteration,&#xD;
    average the results, and plot them on a graph. Customer Satisfaction is plotted on the Y axis, and the iterations are&#xD;
    on the X axis.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Analysis&#xD;
&lt;/h3>&#xD;
&lt;h4>&#xD;
    Using Customer Satisfaction to monitor project execution&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Customer Satisfaction is used as a &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../../practice.mgmt.perf_meas_setup.extend_pract-ibm/customcategories/project_execution_metrics_C29D56DC.html&quot;&#xD;
     guid=&quot;_Y_xjcLQoEd6HgZ8EwRW1Og&quot;>Project Execution metric&lt;/a> to help a team monitor and steer their project&#xD;
    performance. As level of satisfaction is tracked, trends are identified to help the team predict whether they are&#xD;
    likely to deliver a system that is valuable to its stakeholders. If customer satisfaction isn't high enough, the team&#xD;
    can take appropriate corrective action to steer the project toward meeting stakeholder expectations.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;strong>Expected trend&lt;/strong> - A team that is incrementally releasing working software, and receiving and acting on&#xD;
    frequent stakeholder feedback should expect to see Customer Satisfaction increase over time, resulting in an upward&#xD;
    sloping trend line as the project progresses. Satisfaction should increase as more functionality is delivered.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;strong>Downward slope -&lt;/strong> When customer satisfaction decreases as the project progresses, it is an indication&#xD;
    of a problem. Several factors can impact the customer's perception of value:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Quality - A rising number of discovered defects will negatively impact stakeholder satisfaction. Analyze &lt;a&#xD;
        class=&quot;elementLinkWithUserText&quot;&#xD;
        href=&quot;./../../../core.tech.common.extend_supp_metrics-ibm/guidances/supportingmaterials/defect_trends_2E2A9ABF.html&quot;&#xD;
         guid=&quot;_AIQmoITEEd2AfZddKTmDRA&quot;>Defect Trends&lt;/a> and &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
        href=&quot;./../../../core.tech.common.extend_supp_metrics-ibm/guidances/supportingmaterials/defect_density_87F8322D.html&quot;&#xD;
         guid=&quot;_Yg1bYITBEd2AfZddKTmDRA&quot;>Defect Density&lt;/a> to determine underlying causes of quality issues and take&#xD;
        action.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Lack of Shared Understanding - If the team is delivering functionality that does not work as stakeholders expect,&#xD;
        satisfaction levels are likely to decrease. Collaborate with stakeholders to clarify requirements. Monitor change&#xD;
        requests to determine if the team is accommodating and adapting to stakeholders changing needs and priorities.&#xD;
        Follow-up on issues in a timely manner.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Prioritization - If the team isn't delivering stakeholders' highest priority features first, the system will not be&#xD;
        perceived as valuable. Adjust plans to focus on those features that are most valuable to stakeholders.&lt;br />&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    &lt;strong>Flat&lt;/strong> - A flat trend line indicates that customer satisfaction is not increasing as the project&#xD;
    progresses and more functionality is delivered. This can occur after a steady incline raises the expectations of the&#xD;
    stakeholders. When the highest priority features have been delivered, stakeholders may not be as excited with the lower&#xD;
    priority features. Pay close attention to the comments provided on surveys. If stakeholders are not specifically&#xD;
    mentioning any new issues, it could be that they are happy with progress. Follow-up with stakeholders to validate their&#xD;
    continued satisfaction.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    Using Customer Satisfaction to monitor capability improvement&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Customer Satisfaction is also used as a &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../../practice.mgmt.perf_meas_setup.extend_pract-ibm/customcategories/capability_improvement_metrics_2E2DA03B.html&quot;&#xD;
     guid=&quot;_kDlPILQoEd6HgZ8EwRW1Og&quot;>Capability Improvement&lt;/a> metric. It helps middle management (project manager, product&#xD;
    owner) and development executives monitor improvements made during the project lifecycle in adopting practices such as&#xD;
    &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../../practice.mgmt.perf_meas_setup.extend_pract-ibm/guidances/supportingmaterials/iterative_development_6A86E97C.html&quot;&#xD;
     guid=&quot;_7_ZcMBJPEd6XR8gtzfa27w&quot;>Iterative Development&lt;/a>, &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../../practice.mgmt.perf_meas_setup.extend_pract-ibm/guidances/supportingmaterials/cont_integration_CA8C1C7E.html&quot;&#xD;
     guid=&quot;_8awzoBJ9Ed6XR8gtzfa27w&quot;>Continuous Integration&lt;/a>, &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../../practice.mgmt.perf_meas_setup.extend_pract-ibm/guidances/supportingmaterials/test_drvn_dev_AE0948E5.html&quot;&#xD;
     guid=&quot;_4Nfh8BJ9Ed6XR8gtzfa27w&quot;>Test-Driven Development&lt;/a>, and &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../../practice.mgmt.perf_meas_setup.extend_pract-ibm/guidances/supportingmaterials/team_change_mgmt_3ACA32CB.html&quot;&#xD;
     guid=&quot;_rqLLUBJ9Ed6XR8gtzfa27w&quot;>Team Change Management&lt;/a>. Operational Executives can also use this metric to monitor&#xD;
    systematic improvement in &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../../practice.mgmt.perf_meas_setup.extend_pract-ibm/customcategories/increase_value_8277C17D.html&quot;&#xD;
    guid=&quot;_sD4pkLbFEd6_i8GY7ieNyA&quot;>Increasing Business Value&lt;/a> across the organization by adopting these practices.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;strong>Expected trend&lt;/strong> - Teams successfully adopting agile practices will consistently show an upward sloping&#xD;
    trend line for Customer Satisfaction. As they incrementally deliver working software according to stakeholder&#xD;
    priorities, satisfaction levels will increase.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;strong>Fast incline After early iterations -&lt;/strong> If stakeholders typically report very low satisfaction levels in&#xD;
    early iterations followed by a dramatic incline, it is likely that teams are not successfully adopting iterative&#xD;
    development. This trend is seen when teams aren't doing any actual development (delivering working software) early in&#xD;
    the lifecycle. Instead, they are performing in more of a waterfall fashion, focusing on requirements and design only.&#xD;
    This trend can also occur when teams are delivering low priority features in early iterations instead of focusing on&#xD;
    those valued most by stakeholders. Provide a coach or mentor to help teams that are new to iterative development, or&#xD;
    that are struggling. Encourage retrospective reviews at the end of each iteration to help teams evaluate their adoption&#xD;
    of iterative development best practices.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;strong>Fast decline at the end of lifecycle&lt;/strong> - This trend can indicate that teams are waiting too long to&#xD;
    address high risk features and seek clarification. If show-stopper issues often arise in later iterations, ensure that&#xD;
    in addition to iterative development, teams are also adopting risk-reduction practices such as &lt;a&#xD;
    class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../../practice.mgmt.perf_meas_setup.extend_pract-ibm/guidances/supportingmaterials/risk_value_lifecycle_D856178B.html&quot;&#xD;
     guid=&quot;_opHtMB5GEd6GVo4qxneYow&quot;>Risk Value Lifecycle&lt;/a>. Defects that are discovered very late in the lifecycle (often&#xD;
    the result of introducing last minute changes near the end of a release) can also cause a dramatic drop in customer&#xD;
    satisfaction. Ensure that teams are following iterative development and release planning best practices to minimize&#xD;
    surprises at the end of the lifecycle. Adoption of Test-Driven Development allows for earlier, less costly detection of&#xD;
    defects.&lt;br />&#xD;
    &lt;br />&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Frequency and reporting&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Surveys are delivered regularly throughout the lifecycle and post-delivery to monitor stakeholder satisfaction levels.&#xD;
    Frequency will vary by project. Some projects benefit from conducting a survey following each iteration demo. Others&#xD;
    find that every six weeks to three months is sufficient. As with all types of stakeholder feedback, it is best to learn&#xD;
    of a potential problem early, than to wait so long that a particular stakeholder concern becomes a real problem.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    After each survey period, a Customer Satisfaction chart is generated by the team lead or product owner and reviewed&#xD;
    with the team to help identify trends.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;br />&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Collection and reporting tools&#xD;
&lt;/h3>Responses are typically captured in a spreadsheet, database, or online survey tool.&lt;br />&#xD;
&lt;h3>&#xD;
    Assumptions and prerequisites&#xD;
&lt;/h3>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Key stakeholders are committed to providing frequent feedback&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Surveys are conducted at regular, frequent intervals&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        The team delivers working software each iteration&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        The team has a prioritized backlog of work items that is maintained on a daily basis.&lt;br />&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h3>&#xD;
    Pitfalls, advice, and countermeasures&#xD;
&lt;/h3>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Confirm that the purpose of the survey is clear to your stakeholders to maximize participation.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        In order to monitor trends over time with this metric, it is critical that survey questions remain unchanged&#xD;
        throughout the project. Additional questions or rewording of existing questions can significantly impact results.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Customer Satisfaction is often a lagging indicator. The state of the system in early iterations can have a residual&#xD;
        impact on survey responses in later iterations. If stakeholders perceived major quality issues early on in the&#xD;
        lifecycle, it may take a while for their satisfaction levels to rise after the issues were resolved.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Ensure that each survey question provides data that is actionable. If the team cannot identify specific steps to&#xD;
        take based on survey responses, then the survey is not useful.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Conduct the first survey early in the lifecycle in order to establish a baseline against which to assess progress.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Following up on survey ratings is critical. Collaborate with responses and take corrective action to address issues&#xD;
        and concerns.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Responses in the same survey period that vary widely should be analyzed carefully. Stakeholder disagreements might&#xD;
        be discovered.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Too many surveys or overly complex questions can negatively impact results. Ensure that completing a survey is&#xD;
        simple and relatively quick for your Responses. Automated, Web-based surveys can reduce the overhead in survey&#xD;
        participation and analysis.&lt;br />&#xD;
    &lt;/li>&#xD;
&lt;/ul>&lt;br /></mainDescription>
</org.eclipse.epf.uma:ContentDescription>
