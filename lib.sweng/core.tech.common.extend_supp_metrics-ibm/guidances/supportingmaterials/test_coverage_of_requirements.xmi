<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:ContentDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmlns:epf="http://www.eclipse.org/epf" epf:version="1.5.1" xmlns:rmc="http://www.ibm.com/rmc" rmc:version="7.5.1" xmi:id="-xLVhyNbMphb26MZlDxWwTg" name="new_supporting_material,_IJVvoCthEd6wLLxMlDYvug" guid="-xLVhyNbMphb26MZlDxWwTg" changeDate="2010-10-20T09:46:31.741-0700" version="7.5.0">
  <mainDescription>&lt;h3>&#xD;
    Purpose&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    This metric exposes requirements that do not have test cases. The ultimate goal of this metric is to ensure that all&#xD;
    requirements can be validated and that they work as intended.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Definition&#xD;
&lt;/h3>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Number of test cases per requirement&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Number of requirements with no associated test cases&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h3>&#xD;
    Analysis&#xD;
&lt;/h3>&#xD;
&lt;p style=&quot;MARGIN: 0in 0in 0pt&quot; class=&quot;MsoNormal&quot;>&#xD;
    Software that implements requirements with inadequate test coverage may not work as intended or may have defects. The&#xD;
    team should expect 100% coverage of requirements. Verification of coverage requires traceability between requirements&#xD;
    and test artifacts.&#xD;
&lt;/p>&lt;br />&#xD;
&lt;p style=&quot;MARGIN: 0in 0in 0pt&quot; class=&quot;MsoNormal&quot;>&#xD;
    With some exceptional cases, such as a requirement that can be satisfied by demonstration, a requirement might not need&#xD;
    a corresponding test case, but could be verified by other verification method. In this case, the team should make sure&#xD;
    that all requirements are verified by checking at the Verification matrix report.&lt;br />&#xD;
    &lt;br />&#xD;
    Tracing requirements to test cases can yield a 10% to 30% defect reduction over several years. Not all requirements&#xD;
    will have the same number of test cases or amount of test effort applied.&lt;br />&#xD;
    &lt;br />&#xD;
    This pie chart shows the percentage of requirements that have and do not have associated test cases.&lt;br />&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;img alt=&quot;Test Coverage of Requirements&quot; src=&quot;./resources/test_coverage_of_req.gif&quot; width=&quot;287&quot; height=&quot;233&quot; />&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Frequency and reporting&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Monitor Test Coverage of Requirements each iteration. For iterative development, Test Coverage of Requirements should&#xD;
    be close to 100% for requirements planned for&amp;nbsp;that iteration.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Collection and reporting tools&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Test to Requirements traceability information can be obtained from&amp;nbsp;a Requirements Traceability Matrix. Tools like&#xD;
    IBM&amp;reg; Rational&amp;reg; DOORS&amp;reg;, IBM&amp;reg; Rational&amp;reg; Requirements Composer&amp;reg;, IBM&amp;reg; Rational&amp;reg; Requisite Pro&amp;reg;, and&amp;nbsp;IBM&amp;reg; Rational&amp;reg;&#xD;
    Team Concert&amp;reg; can be used to collect the data.&amp;nbsp;IBM&amp;reg; Rational&amp;reg; Quality Manager&amp;reg; provides a Requirements Not Covered&#xD;
    by Test report.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    IBM&amp;reg; Rational&amp;reg; Insight&amp;reg; provides full support&amp;nbsp;for reporting the data.&lt;br />&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Pitfalls, advice, and countermeasures&#xD;
&lt;/h3>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        When the metric shows 100%&amp;nbsp; coverage and the team believes that test coverage is good, watch out for the&#xD;
        following circumstances:&amp;nbsp; &#xD;
        &lt;ul>&#xD;
            &lt;li>&#xD;
                The quality of the tests themselves may be bad.&#xD;
            &lt;/li>&#xD;
            &lt;li>&#xD;
                Most requirements need more than one test case.&#xD;
            &lt;/li>&#xD;
            &lt;li>&#xD;
                The requirements may be wrong or misunderstood by the test case developer, so 100% coverage of them is a&#xD;
                waste of time.&#xD;
            &lt;/li>&#xD;
            &lt;li>&#xD;
                100% test coverage is the minimum set of tests or only covers incidental cases&#xD;
            &lt;/li>&#xD;
            &lt;li>&#xD;
                The team is trying to get 100% coverage, despite knowing they have bad requirements.&#xD;
            &lt;/li>&#xD;
        &lt;/ul>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        A 100% test to requirements coverage does not always mean that the requirements are thoroughly tested; the&#xD;
        following items are indicators of measurement pitfalls and should be used to corroborate this metric: &#xD;
        &lt;ul>&#xD;
            &lt;li>&#xD;
                Defects rejected by the development team with a resolution of &quot;works as intended&quot;, which could imply that&#xD;
                development team and the verification team have different understanding on the requirements.&#xD;
            &lt;/li>&#xD;
            &lt;li>&#xD;
                Defects found after the iteration in which the requirement was tested, the possible reasons are listed in&#xD;
                the pitfalls section&#xD;
            &lt;/li>&#xD;
            &lt;li>&#xD;
                Change requests vs. requirements&#xD;
            &lt;/li>&#xD;
            &lt;li>&#xD;
                Acceptance test failure rate&lt;br />&#xD;
            &lt;/li>&#xD;
        &lt;/ul>&#xD;
    &lt;/li>&#xD;
&lt;/ul></mainDescription>
</org.eclipse.epf.uma:ContentDescription>
