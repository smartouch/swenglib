<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:ContentDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmlns:epf="http://www.eclipse.org/epf" epf:version="1.5.1" xmlns:rmc="http://www.ibm.com/rmc" rmc:version="7.5.1" xmi:id="-xNoAKpglsjsoGJmg7X6Kjg" name="new_supporting_material,_UihDcNvdEd-ZG668GQh--Q" guid="-xNoAKpglsjsoGJmg7X6Kjg" changeDate="2010-10-19T18:03:19.437-0600" version="7.5.1">
  <mainDescription>&lt;h3>&#xD;
    Purpose&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Test Trend is a metric originated by IBM to help teams understand whether their test activities are falling behind&#xD;
    plan.&amp;nbsp;&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Definition&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Count for each unit of time monitored:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        total number of planned test cases&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        total number of attempted test cases&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        total number of completed test cases&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    Because not all test cases are equally important, you can assign weight to the test cases using a relative point&#xD;
    system. Monitor test points for this metric instead of the number of test cases. IBM uses a 10 point scale where 10 is&#xD;
    the most important and 1 is the least.&amp;nbsp; Points are assigned during test planning.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Test cases can be grouped into functional and system tests categories.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Analysis&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Create a Test Trend report, plotting units of time on the X axis and test cases or test points (cumulative) on the Y&#xD;
    axis.&amp;nbsp; Plot a line for &amp;nbsp;the number of planned test cases, the&amp;nbsp;number of attempted test cases, and the&#xD;
    number of completed test cases.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    By tracking against the plan, it is easy to identify when testing activity is falling behind. This typically happens to&#xD;
    projects under schedule pressure. The expected trend is an S-curve. However, if the S-curve is steep, the team should&#xD;
    challenge the feasibility of the plan&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Establish a recommended&amp;nbsp;15% threshold between successful and planned test cases&amp;nbsp;to trigger corrective actions&#xD;
    as necessary.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    For a large project&amp;nbsp;with hundreds or thousands of&amp;nbsp;test cases it is helpful to monitor at the component&#xD;
    level&amp;nbsp;for better&amp;nbsp;visibility. Consider using a tabular format to report on this metric.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Watch out for cases where overall testing activity progress is on track, but a particular component is falling behind&#xD;
    schedule.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Frequency and reporting&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Monitor&amp;nbsp;Test Trend&amp;nbsp;weekly to ensure that testing activity&amp;nbsp;issues are discovered quickly. Frequent&#xD;
    monitoring can reduce the risk of schedule slippage.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Collection and reporting tools&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Test activity is captured in IBM&amp;reg; Rational&amp;reg; Quality Manager&amp;reg; and reported in the&amp;nbsp;Test Execution Trends&#xD;
    report.&amp;nbsp;&lt;br />&#xD;
&lt;/p></mainDescription>
</org.eclipse.epf.uma:ContentDescription>
