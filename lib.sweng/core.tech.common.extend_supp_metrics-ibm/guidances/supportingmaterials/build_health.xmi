<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:ContentDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmlns:rmc="http://www.ibm.com/rmc" rmc:version="7.5.1" xmlns:epf="http://www.eclipse.org/epf" epf:version="1.5.1" xmi:id="-GmeNWvIQtScTDwBh2Ao1Og" name="build_health,_zJU3EHyBEd6NKrqY_I6iFg" guid="-GmeNWvIQtScTDwBh2Ao1Og" changeDate="2011-10-10T14:29:52.663-0700" version="7.5.0">
  <mainDescription>&lt;h3>&#xD;
    Purpose&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    This metric helps teams assess their adoption of&amp;nbsp; iterative development best practices.&amp;nbsp;It measures the&#xD;
    intervals&amp;nbsp;(in units of time) that you have a failed&amp;nbsp;build, and the intervals (in units of time) that you have&#xD;
    a clean build. Iterative development involves incrementally building working software. As a result, the build should&#xD;
    not stay failed for long, especially at the end of the iteration.&amp;nbsp;&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    An important piece of information to capture along with this metric is the number of total tests that are used to test&#xD;
    the build.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    Definition&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Number of tests = total number of tests in a test suite at a given time (you may also calculate the percentage of&#xD;
    attempted and passed test cases)&lt;br />&#xD;
    &lt;br />&#xD;
    Clean build range = interval of time that the build remains clean&lt;br />&#xD;
    &lt;br />&#xD;
    Failed build Range = interval of time that the build remains failed&lt;br />&#xD;
&lt;/p>&lt;br />&#xD;
&lt;br />&#xD;
&lt;h3>&#xD;
    Analysis&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    A good way to monitor iteration&amp;nbsp;Build&amp;nbsp;Health over time is to plot the data on a line chart. The&#xD;
    following&amp;nbsp;figure shows an example of a&amp;nbsp;Build Health chart.&amp;nbsp; The last 10 weekly integration builds are&#xD;
    shown.&amp;nbsp;Incomplete builds are not shown. The green area shows the interval of&amp;nbsp;time when the build stays&#xD;
    healthy, whereas&amp;nbsp;the red area shows the time when the&amp;nbsp;build failed.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&#xD;
    &lt;img alt=&quot;Build Health Report&quot; src=&quot;./resources/build_health_report.gif&quot; width=&quot;472&quot; height=&quot;353&quot; />&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;strong>Expected trend -&lt;/strong> A constant green area is ideal, indicating that the build never fails and continuous&#xD;
    build integration is achieved. Typically, the build should stay green most of the time. Red intervals change to green&#xD;
    quickly. The number of test cases grows over time.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;strong>Long periods of failed builds&lt;/strong> - Over one day is not acceptable. This may indicate problems resolving&#xD;
    compilation or test failures. &lt;span class=&quot;textItem&quot; tabindex=&quot;0&quot;>When a build fails, the failure should be resolved as&#xD;
    soon as possible. A large red interval means that the team is delivering bad or untested code, or that the team is not&#xD;
    acting to resolve the failure. This can impact the quality of a project significantly.&lt;/span>&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;strong>Frequent failed builds&lt;/strong> - This trend&amp;nbsp;indicates build instability and issues with the overall&#xD;
    quality of the code. If the&amp;nbsp;system is complex and integrating new change sets causes the build to fail, the&#xD;
    team&amp;nbsp;is not&amp;nbsp;doing a good job&amp;nbsp;of impact analysis. All dependencies are not identified prior to code&#xD;
    change, or the team has not done a good job in verifying the code before promoting to the integrated workspace.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    &lt;span tabindex=&quot;0&quot;>Collection and reporting tools&lt;/span>&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    &lt;span class=&quot;textItem&quot; tabindex=&quot;0&quot;>&lt;span class=&quot;textItem&quot; tabindex=&quot;0&quot;>IBM&amp;reg; Rational&amp;reg; Team Concert&amp;reg; collects build&#xD;
    health data. &amp;nbsp;&lt;/span>IBM&amp;reg; Rational&amp;reg; Insight&amp;reg; and&amp;nbsp;IBM&amp;reg; Rational&amp;reg; ClearQuest ALM&amp;reg;&amp;nbsp;&amp;nbsp;report on this&#xD;
    metric.&lt;/span>&#xD;
&lt;/p></mainDescription>
</org.eclipse.epf.uma:ContentDescription>
