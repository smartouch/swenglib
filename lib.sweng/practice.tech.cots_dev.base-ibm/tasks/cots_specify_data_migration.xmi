<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:TaskDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmlns:rmc="http://www.ibm.com/rmc" rmc:version="7.5.1" xmlns:epf="http://www.eclipse.org/epf" epf:version="1.5.1" xmi:id="-1yxWkuN3avirsMGFYf3oCw" name="cots_specify_data_migration,_yycHbuwiEd-sjp03to1LnQ" guid="-1yxWkuN3avirsMGFYf3oCw" version="7.1.0">
  <sections xmi:id="_yycHcewiEd-sjp03to1LnQ" name="Define Migration Scope" guid="_yycHcewiEd-sjp03to1LnQ">
    <sectionDescription>&lt;a id=&quot;Data_Migration_Scope&quot; name=&quot;Data_Migration_Scope&quot;>&lt;/a> &#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table&#xD;
    style=&quot;BORDER-BOTTOM: rgb(128,128,128) 1px solid; BORDER-LEFT: rgb(128,128,128) 1px solid; BORDER-TOP: rgb(128,128,128) 1px solid; BORDER-RIGHT: rgb(128,128,128) 1px solid&quot;&#xD;
     border=&quot;1&quot; cellspacing=&quot;0&quot; bordercolor=&quot;#808080&quot; bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot; cellpadding=&quot;4&quot;&#xD;
    width=&quot;100%&quot;>&#xD;
        &lt;tbody valign=&quot;center&quot;>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;5%&quot;>&#xD;
                    &lt;b>Purpose:&lt;/b>&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;95%&quot;>&#xD;
                    To define the scope of the migration&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
        &lt;/tbody>&#xD;
    &lt;/table>&lt;br />&#xD;
    &lt;p>&#xD;
        The first task to do when you plan to migrate data to a new database is to define the scope of the migration. Some&#xD;
        specific elements of this are:&#xD;
    &lt;/p>&#xD;
    &lt;ul>&#xD;
        &lt;li>&#xD;
            Identifying the sources of the data to be migrated and their location.&#xD;
        &lt;/li>&#xD;
        &lt;li>&#xD;
            Identifying the systems that use the current data sources and the systems that will be using the new database.&#xD;
        &lt;/li>&#xD;
        &lt;li>&#xD;
            Identifying data not currently held electronically and how to enter them into the new system.&#xD;
        &lt;/li>&#xD;
        &lt;li>&#xD;
            Determining if the source data is to be retired after migration. If the source data is to continue being used,&#xD;
            then maintenance of the data in both its original source and in the new database can be an issue.&#xD;
        &lt;/li>&#xD;
    &lt;/ul>&#xD;
    &lt;p>&#xD;
        In addition, you should identify the relevant subset of the source data. Data migration projects do not happen&#xD;
        independently. Rather, they are spawned from other development efforts, such as projects to evolve or replace a&#xD;
        legacy system. The volume of historical data that needs to be migrated is derived from the needs of these&#xD;
        development efforts because it is usually not valuable to migrate all the data of the existing system. Below are&#xD;
        some ideas of elements that can help determining such scope:&#xD;
    &lt;/p>&#xD;
    &lt;ul>&#xD;
        &lt;li>&#xD;
            Historical data from the old system might not be able to be converted into the new system's format. For&#xD;
            example, it might no longer have the same meaning because of data structure changes.&#xD;
        &lt;/li>&#xD;
        &lt;li>&#xD;
            Historical data from prior years might only need to be kept at a summary level.&#xD;
        &lt;/li>&#xD;
        &lt;li>&#xD;
            There might be mandatory requirements, such as tax regulations requiring detailed historical information to be&#xD;
            kept, but not necessarily converted for a specific period of time.&#xD;
        &lt;/li>&#xD;
    &lt;/ul>&#xD;
    &lt;p>&#xD;
        Ideally, the completion of data migration should immediately precede the start of production running of the new&#xD;
        system. However, when the data is very volatile or very large or when the validation of the migration results is a&#xD;
        lengthy process, amendments to the migrated data might be necessary. This is especially true where manual data has&#xD;
        to be collected, verified, and then entered to the automated system; in these circumstances, data capture might&#xD;
        take many months.&#xD;
    &lt;/p>&#xD;
    &lt;p>&#xD;
        In such cases, you need to plan and define the maintenance procedures to keep the migrated data up-to-date in any&#xD;
        interim period between the completion of the data migration and the initiation of production running. These&#xD;
        procedures need to strike a balance between economy (they will not normally be in use for very long) and accuracy&#xD;
        (they must not introduce errors into the converted data). They should also incorporate controls and audit trails as&#xD;
        applicable.&lt;br />&#xD;
    &lt;/p>&#xD;
&lt;/div></sectionDescription>
  </sections>
  <sections xmi:id="_yycHcuwiEd-sjp03to1LnQ" name="Understand Data Sources Through Data Profiling" guid="_yycHcuwiEd-sjp03to1LnQ">
    <sectionDescription>&lt;a id=&quot;Data_Profiling&quot; name=&quot;Data_Profiling&quot;>&lt;/a> &#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table&#xD;
    style=&quot;BORDER-BOTTOM: rgb(128,128,128) 1px solid; BORDER-LEFT: rgb(128,128,128) 1px solid; BORDER-TOP: rgb(128,128,128) 1px solid; BORDER-RIGHT: rgb(128,128,128) 1px solid&quot;&#xD;
     border=&quot;1&quot; cellspacing=&quot;0&quot; bordercolor=&quot;#808080&quot; bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot; cellpadding=&quot;4&quot;&#xD;
    width=&quot;100%&quot;>&#xD;
        &lt;tbody valign=&quot;center&quot;>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;5%&quot;>&#xD;
                    &lt;b>Purpose:&lt;/b>&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;95%&quot;>&#xD;
                    To establish the Data Profile of the different data sources&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
        &lt;/tbody>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Now that you have identified the different data sources, you can start to analyze them to establish their Data Profile.&#xD;
    The Data Profile is a collection of information on the data content, structure, and quality that will be stored in the&#xD;
    Data Migration Specification.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The detailed steps for establishing the Data Profile are as follows:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#Collect_Information&quot;>Collect Information&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#Analyze_Sources&quot;>Analyze Data Sources&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#Profile_Sources&quot;>Profile Data Sources Attributes&lt;/a>&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;Collect_Information&quot; name=&quot;Collect_Information&quot;>Collect Information&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    The first step in data profiling is to gather the metadata describing the data sources. This may include source&#xD;
    programs, dictionary or repository descriptions, relational catalog information, previous project documentation, and&#xD;
    anything else available that could shed light on the meaning of the data. If the system using the data was developed&#xD;
    using the RUP, you can use data model, use cases&lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../core.tech.common.extend_supp/workproducts/use_case_22BE66E2.html&quot; guid=&quot;_0VGbUMlgEdmt3adZL5Dmdw&quot;>,&lt;/a>&#xD;
    and the &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../practice.tech.use_case_driven_dev.base/guidances/guidelines/uc_realizations_448DDA77.html&quot;&#xD;
    guid=&quot;_2uan8NbyEdqu5o2S60g5LA&quot;>Use-Case Realizations&lt;/a> as sources to understand how data is used by the system.&#xD;
    Interviewing the original developers, if they are available, or the database administrator who manages the data can&#xD;
    also be useful.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    However, documentation (other than information that is automatically maintained as part of the system or is reverse&#xD;
    engineered) should be considered suspect. It was valid at some point but typically decays in correctness over time.&#xD;
    Legacy systems are often thinly documented at their creation, and documentation often doesn't keep up with the changes&#xD;
    made along the way. Even if it is not current, existing metadata is often the only information that is available about&#xD;
    data sources and data semantics. The profiling process will expose the dissonance between metadata and the real data&#xD;
    and fill in the most important parts of the missing information.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;Analyze_Sources&quot; name=&quot;Analyze_Sources&quot;>Analyze Data Sources&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    The second step in data profiling is to develop a map of the data sources. This map shows how data fields are stored&#xD;
    and establishes rules for dealing with redefines and repeating groups of data within the data structures.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    If the data source is relational, the map can be extracted directly from the database schema. Because these structures&#xD;
    are enforced by the DBMS, there is no need to question their validity.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    If the data source is anything other than relational, you need to use use the metadata in conjunction with the data to&#xD;
    get a normalized form of the data. You need especially to pay attention to &quot;overloaded&quot; attributes. &quot;Overloading&quot; is&#xD;
    the process of storing multiple facts in the same attribute.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    When this profiling step is completed, you can perform a sample of full extraction of the data sources, in normalized&#xD;
    form, to go further in the data profiling process. Usually, this extraction is done with the extraction scripts of the&#xD;
    migration components because it is also a good way to test them.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;Profile_Sources&quot; name=&quot;Profile_Sources&quot;>Profile Data Source Attributes&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    The third step in data profiling is to determine the content, domain, and quality of the data in each attribute and to&#xD;
    establish the semantics behind each attribute. It is important to perform this operation with the actual source data,&#xD;
    as the documented metadata might be incorrect.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    This operation gives you the opportunity to identify:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Attributes documented for one use but used for another&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Attributes documented but not used&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Inconsistencies between the data content of an attribute and its semantic meaning&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Attribute's cardinality to identify dead attributes (those containing just one value)&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    Legacy and even relational systems commonly use &quot;de-normalization&quot; and data duplication as a result of attempts to&#xD;
    improve the performance. They also frequently lack primary and foreign key support. That means that you must analyze&#xD;
    the source tables to identify the functional dependencies between attributes and to find primary and foreign key&#xD;
    candidates.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    When the attribute profiling is finished, it needs to be reviewed at two different levels. The first level is to decide&#xD;
    whether or not to migrate the attribute. You might choose not to migrate an attribute if it contains no useful&#xD;
    information or if the data is of such poor quality that it cannot be migrated without corrupting the target. The second&#xD;
    level is to determine whether the attribute needs to be scrubbed during the migration.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    When quality problems have been discovered during the profiling, you need to perform some data cleansing; removing or&#xD;
    amending data that is incorrect, duplicated, improperly formatted, or incomplete. This operation is usually called&#xD;
    &lt;i>data scrubbing&lt;/i>.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_yycHb-wiEd-sjp03to1LnQ" name="Define the Mapping Between Data Sources and Target Database" guid="_yycHb-wiEd-sjp03to1LnQ">
    <sectionDescription>&lt;a id=&quot;Source_Target_Mapping&quot; name=&quot;Source_Target_Mapping&quot;>&lt;/a> &#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table&#xD;
    style=&quot;BORDER-BOTTOM: rgb(128,128,128) 1px solid; BORDER-LEFT: rgb(128,128,128) 1px solid; BORDER-TOP: rgb(128,128,128) 1px solid; BORDER-RIGHT: rgb(128,128,128) 1px solid&quot;&#xD;
     border=&quot;1&quot; cellspacing=&quot;0&quot; bordercolor=&quot;#808080&quot; bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot; cellpadding=&quot;4&quot;&#xD;
    width=&quot;100%&quot;>&#xD;
        &lt;tbody valign=&quot;center&quot;>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;5%&quot;>&#xD;
                    &lt;b>Purpose:&lt;/b>&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;95%&quot;>&#xD;
                    To describe the mapping between the source database elements and the corresponding target database&#xD;
                    elements&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
        &lt;/tbody>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    The two main inputs of this step are the data profile elaborated in the previous step and the Physical Data Model of&#xD;
    the target database.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    A popular misconception about data mapping is that it can be performed against logical data models. However, since the&#xD;
    source data is in a physical data format, and we need to migrate this data into the new physical data model, it is more&#xD;
    practical to map between these physical forms than deal with indirect mappings by means of a logical data model.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Important considerations to address are:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        If there are multiple sources for the same target attribute, how to address conflicts&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        If there is no source for an attribute, how will the data be provided&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    To successfully perform this step, the database designer needs to work with a business designer possessing an intimate&#xD;
    knowledge of the data that needs to be migrated and a business analyst with knowledge of both the source and target&#xD;
    systems.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The mapping should be recorded in the Data Migration Specification.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The two main sources of input to this step are the data profile elaborated in the previous step and the Physical Data&#xD;
    Model of the target database.&lt;br />&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_yycHcOwiEd-sjp03to1LnQ" name="Identify Manual and Automated Data Migration" guid="_yycHcOwiEd-sjp03to1LnQ">
    <sectionDescription>&lt;a id=&quot;Manual_Auto_Migration&quot; name=&quot;Manual_Auto_Migration&quot;>&lt;/a> &#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table&#xD;
    style=&quot;BORDER-BOTTOM: rgb(128,128,128) 1px solid; BORDER-LEFT: rgb(128,128,128) 1px solid; BORDER-TOP: rgb(128,128,128) 1px solid; BORDER-RIGHT: rgb(128,128,128) 1px solid&quot;&#xD;
     border=&quot;1&quot; cellspacing=&quot;0&quot; bordercolor=&quot;#808080&quot; bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot; cellpadding=&quot;4&quot;&#xD;
    width=&quot;100%&quot;>&#xD;
        &lt;tbody valign=&quot;center&quot;>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;5%&quot;>&#xD;
                    &lt;strong>Purpose&lt;/strong>:&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;95%&quot;>&#xD;
                    To identify which parts of the data sources can be automatically migrated and which parts should be&#xD;
                    migrated manually&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
        &lt;/tbody>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    When you have elaborated the data profiles and data mapping of the various data sources, you should identify which&#xD;
    parts of the data migration can be automatically performed and which parts need to be migrated through manual&#xD;
    procedures.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Whenever possible, entry of manually converted data should be performed using the standard data entry processes of the&#xD;
    new system. Occasionally, specially built conversion processes are unavoidable. A typical example is the bulk batch&#xD;
    entry of data which would normally be entered interactively, but where volumes are too high to make interactive entry&#xD;
    practical.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The manually migrated data can be identified in the Data Mapping Table contained in the Data Migration&#xD;
    Specification.&lt;br />&#xD;
&lt;/p></sectionDescription>
  </sections>
  <purpose>&lt;a id=&quot;Top&quot; name=&quot;Top&quot;>&lt;/a> &#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        To specify the data migration by defining its scope, its data profile, and the mapping between the data sources and&#xD;
        the target database&#xD;
    &lt;/li>&#xD;
&lt;/ul></purpose>
</org.eclipse.epf.uma:TaskDescription>
